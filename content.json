{"posts":[{"title":"[Database] Bustub Buffer Pool Manager Implementation","text":"Implement a buffer pool manager for a DBMS, from scratch, in C++. Per CMU policy, Bustub solution should not be made public. Hence, only code snippets and logic are shown here. If you need to see the code, email me: yy4108@nyu.edu. I am on my train to Qingdao right now, to see a beautiful girl. I am not so sure about how I feel, excited, but at the same time nervous. It is even freezing in Shanghai recently, let alone Qingdao. It is my first time, travelling so far, just to see someone. I want to be productive on a train, but it is not easy. Writing something about buffer pool manager will probably calm me down. We will follow the guides and instruction of Andy Pavlo, and his CMU 15-445 course, to implement a buffer pool manager for a database management system, in C++. First, let me prove myself with a Gradescoppe screenshot. You can indeed be convinced that I know what I will be talking about. LRU-K Replacement PolicyImplementing an eviction policy is always the first step in any buffer pool manager implementation. The reason being that we always need to figure out a way to decide which page (frame) to evict when the buffer pool is full. Per the instruction of CMU, here we will be implementing an LRU-K policy. First let’s take a look at what is expected in an LRU replacer. The LRU-K algorithm evicts a frame whose backward k-distance is maximum of all frames in the replacer. Backward k-distance is computed as the difference in time between current timestamp and the timestamp of kth previous access. A frame with fewer than k historical accesses is given +inf as its backward k-distance. When multiple frames have +inf backward k-distance, the replacer evicts the frame with the earliest overall timestamp (i.e., the frame whose least-recent recorded access is the overall least recent access, overall, out of all frames). The maximum size for the LRUKReplacer is the same as the size of the buffer pool since it contains placeholders for all of the frames in the BufferPoolManager. However, at any given moment, not all the frames in the replacer are considered to be evictable. The size of LRUKReplacer is represented by the number of evictable frames. The LRUKReplacer is initialized to have no frames in it. Then, only when a frame is marked as evictable, replacer’s size will increase. With the basic idea in mind, let’s discuss how to implement in detail. 1LRUKReplacer::LRUKReplacer(size_t num_frames, size_t k) : replacer_size_(num_frames), k_(k) {} First, implement the constructor. num_frames is the number of total frames available, and the k_ here should be the number of evictable frames. The main logic of LRU-K is in the Evict function. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950auto LRUKReplacer::Evict(frame_id_t *frame_id) -&gt; bool { std::lock_guard&lt;std::mutex&gt; lock(latch_); if (node_store_.empty()) { // there is no evictable frame return false; } size_t max_distance = 0; frame_id_t candidate = -1; bool found_infinite = false; for (auto &amp;pair : node_store_) { auto &amp;node = pair.second; if (!node.is_evictable_ || node.history_.size() &lt; k_) { // if it has less than k history elements, its k distance is set to +inf if (node.is_evictable_ &amp;&amp; node.history_.size() &lt; k_) { // there hasn't been an element whose k distance is +inf if (!found_infinite) { max_distance = std::numeric_limits&lt;size_t&gt;::max(); candidate = node.fid_; found_infinite = true; } else { // based on LRU, if there are multiple frames with +inf k distance // evict the one with the smallest timestamp if (node.history_.front() &lt; node_store_[candidate].history_.front()) { candidate = node.fid_; } } } // continue the execution, skip this node continue; } size_t distance = current_timestamp_ - node.history_.front(); if (distance &gt; max_distance) { max_distance = distance; candidate = node.fid_; } } if (candidate != -1) { *frame_id = candidate; node_store_.erase(candidate); curr_size_--; return true; } return false;} The logic is simple: check all nodes that are marked evictable by the replacer. If it has less than k elements, then its k distance is set to infinite (the most likely to be replaced). If we have multiple +inf distance nodes, then fall back to the original LRU policy. Just pick the oldest among these +inf nodes. (This is the purpose that found_infinite is servering) Otherwise, if all evictable pages have more than k access records, follow the LRU-K policy, and pick the oldest. RecordAccess function is also important. It should be called anytime we touch a frame (read/write it from the buffer pool manager). 12345678910111213141516171819202122232425262728void LRUKReplacer::RecordAccess(frame_id_t frame_id, [[maybe_unused]] AccessType access_type) { std::lock_guard&lt;std::mutex&gt; lock(latch_); // If frame id is invalid (ie. larger than replacer_size_), throw an exception. if (frame_id &gt;= static_cast&lt;int32_t&gt;(replacer_size_)) { throw Exception(ExceptionType::OUT_OF_RANGE, &quot;frame id is out of range&quot;); } ++current_timestamp_; // Check if the frame_id exists in node_store_. auto it = node_store_.find(frame_id); if (it == node_store_.end()) { // If not found, initialize a new LRUKNode and insert it into node_store_. LRUKNode new_node; new_node.fid_ = frame_id; new_node.history_.push_back(current_timestamp_); new_node.k_ = k_; // Assuming k_ is a property you want to set during initialization. node_store_.emplace(frame_id, std::move(new_node)); } else { // If found, update the existing node. auto &amp;node = it-&gt;second; if (node.history_.size() &gt;= k_) { node.history_.pop_front(); // Ensure only the last k timestamps are kept. } node.history_.push_back(current_timestamp_); }} fist check if the page that you are trying to access is actually legal. If not, raise an exception. If the LRU node is already in the Hash Map, just update the node history (evict the oldest if there is more than K accesses) if not found, init a new node element in the hash map. SetEvictable is simple, you just need to check if the frame_id you are setting is legal and can actually be found in the hash map. Then you set evictablity based on the parameter. Finally, remember to update the current_size_, which represents the number of evictable pages. 12345678910111213141516171819void LRUKReplacer::SetEvictable(frame_id_t frame_id, bool set_evictable) { std::lock_guard&lt;std::mutex&gt; lock(latch_); // If frame id is invalid (ie. larger than replacer_size_), throw an exception. if (frame_id &gt;= static_cast&lt;int32_t&gt;(replacer_size_)) { throw Exception(ExceptionType::OUT_OF_RANGE, &quot;frame id is out of range&quot;); } auto it = node_store_.find(frame_id); if (it == node_store_.end()) { throw Exception(ExceptionType::OUT_OF_RANGE, &quot;Frame ID does not exist, cannot find the frame.&quot;); } auto &amp;node = it-&gt;second; if (node.is_evictable_ != set_evictable) { node.is_evictable_ = set_evictable; curr_size_ += set_evictable ? 1 : -1; }} The last componenet of an LRU is a Remove function, which removes everything from the replacer related with a certain page. 12345678910111213141516171819oid LRUKReplacer::Remove(frame_id_t frame_id) { std::lock_guard&lt;std::mutex&gt; lock(latch_); // If frame id is invalid (ie. larger than replacer_size_), throw an exception. if (frame_id &gt;= static_cast&lt;int32_t&gt;(replacer_size_)) { throw Exception(ExceptionType::OUT_OF_RANGE, &quot;frame id is out of range&quot;); } auto it = node_store_.find(frame_id); if (it == node_store_.end()) { return; } auto &amp;node = it-&gt;second; if (node.is_evictable_) { curr_size_--; } node_store_.erase(it);} check legal find the actual element update the hash map Disk Scheduler and Manager The disk scheduler can be used by other components (in this case, your BufferPoolManager in Task #3) to queue disk requests, represented by a DiskRequest struct (already defined in src/include/storage/disk/disk_scheduler.h). The disk scheduler will maintain a background worker thread which is responsible for processing scheduled requests. The disk scheduler will utilize a shared queue to schedule and process the DiskRequests. One thread will add a request to the queue, and the disk scheduler’s background worker will process the queued requests. We have provided a Channel class in src/include/common/channel.h to facilitate the safe sharing of data between threads, but feel free to use your own implementation if you find it necessary. This is actually quite easy, and I think the main challenge is to familarize yourself with the Promise and Future in C++ 17. (Cool stuff, but reminds me deeply of the trauma I had with JavaScript’s Promise and Future). The main challenge is to implement a thread safe channel construct, which has been provided already. The rest is very straightforward, as long as you are familiar with the move semantics. 12345678910111213141516void DiskScheduler::Schedule(DiskRequest r) { request_queue_.Put(std::make_optional(std::move(r))); }void DiskScheduler::StartWorkerThread() { while (true) { auto request = request_queue_.Get(); if (!request.has_value()) { break; } if (request-&gt;is_write_) { disk_manager_-&gt;WritePage(request-&gt;page_id_, request-&gt;data_); } else { disk_manager_-&gt;ReadPage(request-&gt;page_id_, request-&gt;data_); } request-&gt;callback_.set_value(true); }} 1234struct DiskRequest { // some other code std::promise&lt;bool&gt; callback_;}; Since the DiskRequest contains a Promise object, it cannot be copied, but only moved to the shared queue. After the thread has finished its job, it sets the flag in the callback Promise. Buffer Pool ManagerThis is the main challenge. It is intricate, and delicate, and very hard to debug. It took me several hours to finally get it right (and I an still not sure which part that I touched made things come to the right track). 12345678910111213141516171819202122232425262728293031323334auto BufferPoolManager::NewPage(page_id_t *page_id) -&gt; Page * { std::lock_guard&lt;std::mutex&gt; lock(latch_); frame_id_t frame_id = -1; if (!free_list_.empty()) { // get the page directly from the free list frame_id = free_list_.front(); free_list_.pop_front(); } else if (replacer_-&gt;Evict(&amp;frame_id)) { Page &amp;page = pages_[frame_id]; if (page.IsDirty()) { FlushPage(page.GetPageId()); } page_table_.erase(page.GetPageId()); } else { return nullptr; } *page_id = AllocatePage(); Page &amp;page = pages_[frame_id]; page.ResetMemory(); page.page_id_ = *page_id; page.is_dirty_ = false; page.pin_count_ = 1; page_table_[*page_id] = frame_id; replacer_-&gt;Remove(frame_id); replacer_-&gt;RecordAccess(frame_id, AccessType::Unknown); replacer_-&gt;SetEvictable(frame_id, false); return &amp;page;} This function allocates a new page in the buffer pool manager. The logic is that: If there is a page in the free list, allocate directly. otherwise we need to evict a oage from the LRU replacer (Do remember to detach the original evicted page, delete it from page table, and remove it from the replacer, otherwise the LRU-K policy will not be functioning correctly) don’t forget that if the page is dirty, we need to flush it to disk. initialize the new page with a pin count, a dirty flag, a new page id(unique to this sepcific buffer pool manager), and touch the page with the recordAccess. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879auto BufferPoolManager::FetchPage(page_id_t page_id, [[maybe_unused]] AccessType access_type) -&gt; Page * { std::lock_guard&lt;std::mutex&gt; lock(latch_); auto page_table_it = page_table_.find(page_id); if (page_table_it != page_table_.end()) { // page is in the buffer pool // printf(&quot;Fetching page first phase, page found in buffer pool\\n&quot;); frame_id_t frame_id = page_table_it-&gt;second; Page &amp;page = pages_[frame_id]; page.pin_count_++; replacer_-&gt;RecordAccess(frame_id, access_type); replacer_-&gt;SetEvictable(frame_id, false); return &amp;page; } printf(&quot;Fetching page first phase, page not found in buffer pool\\n&quot;); // page is not in the buffer pool frame_id_t frame_id = -1; if (!free_list_.empty()) { // get the page directly from the free list frame_id = free_list_.front(); free_list_.pop_front(); printf(&quot;get the page from the free list\\n&quot;); } else if (replacer_-&gt;Evict(&amp;frame_id)) { printf(&quot;evict the page from the replacer, frame id is %d\\n&quot;, frame_id); Page &amp;page = pages_[frame_id]; if (page.IsDirty()) { printf(&quot;the page evicted is dirty\\n&quot;); FlushPage(page.GetPageId()); } page_table_.erase(page.GetPageId()); // printf(&quot;the page is getting del\\n&quot;); // DeletePage(page.GetPageId()); // printf(&quot;deletion done\\n&quot;); } else { return nullptr; } // reset the metadata of the new page Page &amp;page = pages_[frame_id]; page.ResetMemory(); page.page_id_ = page_id; page.pin_count_ = 1; // Pin the new page. page.is_dirty_ = false; // schedule a read request DiskRequest read_request; read_request.is_write_ = false; read_request.data_ = page.data_; read_request.page_id_ = page_id; // create the Promise and get its future auto promise = disk_scheduler_-&gt;CreatePromise(); auto future = promise.get_future(); // set the Promise to the callback read_request.callback_ = std::move(promise); // schedule the read request disk_scheduler_-&gt;Schedule(std::move(read_request)); // wait for the read request to finish future.wait(); page_table_[page_id] = frame_id; printf(&quot;Fetching page last phase\\n&quot;); replacer_-&gt;Remove(frame_id); replacer_-&gt;RecordAccess(frame_id, access_type); replacer_-&gt;SetEvictable(frame_id, false); return &amp;page; return nullptr;} FetchPage implementation shares exactly the same logic as the NewPage, the only difference being that after fetching a free page, we need to also fetch the page content from the disk, using the Promise and future. Here we only care about correctness, so wait until IO is finished. 123456789101112131415161718192021222324252627282930auto BufferPoolManager::UnpinPage(page_id_t page_id, bool is_dirty, [[maybe_unused]] AccessType access_type) -&gt; bool { std::lock_guard&lt;std::mutex&gt; lock(latch_); frame_id_t frame_id = -1; auto it = page_table_.find(page_id); if (it == page_table_.end()) { return false; } frame_id = it-&gt;second; Page &amp;page = pages_[frame_id]; if (page.pin_count_ &lt;= 0) { return false; } page.pin_count_--; if (page.pin_count_ == 0) { replacer_-&gt;SetEvictable(frame_id, true); } if (is_dirty) { page.is_dirty_ = true; // FlushPage(page_id); } return true;} The thing that I got wrong with this unpin funciton initially is that here we are not writing to disk, we are only unpinning. To achieve good performance, we want to delay IO as much as possible, instead of writing to the disk everyting we unpins. Flush page is easy, just write to disk, regardless of the dirty bit. The dirty bit will be checked by upper layers. But we do need to clear the dirty flag after writing to disk. 1234567891011121314151617181920212223242526272829303132auto BufferPoolManager::FlushPage(page_id_t page_id) -&gt; bool { // std::lock_guard&lt;std::mutex&gt; lock(latch_); auto it = page_table_.find(page_id); if (it == page_table_.end()) { return false; } frame_id_t frame_id = it-&gt;second; Page &amp;page = pages_[frame_id]; DiskRequest write_request; write_request.is_write_ = true; write_request.data_ = page.GetData(); write_request.page_id_ = page.GetPageId(); // create the Promise and get its future auto promise = disk_scheduler_-&gt;CreatePromise(); auto future = promise.get_future(); // set the Promise to the callback write_request.callback_ = std::move(promise); // schedule the write request disk_scheduler_-&gt;Schedule(std::move(write_request)); // wait for the write request to finish future.wait(); page.is_dirty_ = false; // page_table_.erase(it); return true;} DeletePage12345678910111213141516171819202122232425262728293031auto BufferPoolManager::DeletePage(page_id_t page_id) -&gt; bool { std::lock_guard&lt;std::mutex&gt; lock(latch_); auto it = page_table_.find(page_id); if (it == page_table_.end()) { return true; } frame_id_t frame_id = it-&gt;second; // printf(&quot;deletePage, the page id is %d, and the frame id is %d\\n&quot;, page_id, frame_id); Page &amp;page = pages_[frame_id]; if (page.pin_count_ &gt; 0) { return false; } if (page.IsDirty()) { FlushPage(page_id); } page.ResetMemory(); page.page_id_ = INVALID_PAGE_ID; page.pin_count_ = 0; page.is_dirty_ = false; page_table_.erase(it); // replacer_-&gt;SetEvictable(frame_id, true); replacer_-&gt;Remove(frame_id); free_list_.push_back(frame_id); DeallocatePage(page_id); return true;} DeletePage is also easy, just remember to not delete if the page is still pinned. flush the page if it is dirty. clear all page table and LRU replacer entry. add the page back to the freelist. Ending RemarkIt looks easy, but the logic can be complicated, a little. And it is very hard to debug. Nevertheless, implementing a buffer pool manager is important for me to understand how a disk backed dbms really worked internally. A good lesson to learn, I would say.","link":"/2023/12/19/Database-Bustub-Buffer-Pool-Manager-Implementation/"},{"title":"Implementing a MapReduce Framework with Golang RPC from scratch","text":"I just finished one small piece of work this morning, a MapReduce framework, implemented wit Golang RPC. Before I forget everything, I will document the design and code here. For original source code, it is available at https://github.com/PeterYaoNYU/mit-distributed-sys . I have been coding a lot recently, but not much time has been devoted to writing about what I have done. This is perilous, because I will quickly forget what I have done. Replication is super important for finite state machine as well as leanring computer science. A MapReduce is a paradigm of abstraction for distributed workflows. The orginal paper published by Google is still wildly influentital today, though 2 decades have gone by. It is divided into 2 phases, a map phase, and a reduce phase. I cannot think of a better description than this image found in the original paper: In another words, MR manages and hides all ascpects of distribution. An Abstract view of a MapReduce job – word count Input1 -&gt; Map -&gt; a,1 b,1 Input2 -&gt; Map -&gt; b,1 Input3 -&gt; Map -&gt; a,1 c,1 | | | | | -&gt; Reduce -&gt; c,1 | —–&gt; Reduce -&gt; b,2 ———&gt; Reduce -&gt; a,2 input is (already) split into M files MR calls Map() for each input file, produces list of k,v pairs “intermediate” data each Map() call is a “task” when Maps are done, MR gathers all intermediate v’s for each k, and passes each key + values to a Reduce call final output is set of &lt;k,v&gt; pairs from Reduce()s Implementation of the WorkerThe logic for the worker code is more straightforward, and servers as a good starting point. The worker just first acquire the knowledge of how many reduce there are (this decides how many intermediate output each Map should produce), periodically ask for job from the coordinator, wait for the job to arrive, and based on the RPC reply argument, do either Map job or reduce job. After doing the job, report back to the coordinator that the job asked for has been finished, and it can be assigned future tasks then. 12345678910111213141516171819202122232425262728293031323334func Worker(mapf func(string, string) []KeyValue, reducef func(string, []string) string) { args := GetNReduceArgs{} reply := GetNReduceReply{} call(&quot;Coordinator.GetNReduce&quot;, &amp;args, &amp;reply) nReduce := reply.NReduce for { // 1. Request a task from the coordinator reply, succ := requestTask() if !succ { // fmt.Println(&quot;Request task failed&quot;) return } if reply.TaskType == ExitTask { // fmt.Println(&quot;No task left&quot;) return } if reply.TaskType == MapTask { doMap(mapf, reply.File, reply.TaskId, nReduce) // 3. Report the task is done to the coordinator reportMapDone(reply.TaskId) } else { // 2. Do the reduce task doReduce(reducef, reply.TaskId) // 3. Report the task is done to the coordinator reportReduceDone(reply.TaskId) } }} This is the big framework for the Worker. All we need to do next is to fill in the details. We need to implement: the actual map code and reduce code report back to the coordinator that the job has been done A heartbeat function that peridically asks for more task from the coordinator A writer function that output the intermediate values after Map operation to a shared distributed storage system (Like a Google File System) Let’s fill in the details:This function is asking for tasks periodically 123456func requestTask() (reply *RequestTaskReply, succ bool) { args := RequestTaskArgs{WorkerID: os.Getpid()} reply = &amp;RequestTaskReply{} succ = call(&quot;Coordinator.RequestTask&quot;, &amp;args, reply) return reply, succ} If the task is a Map task, we do the map, and then write to the disk, then report to the coordinator that the map job has been done. One detail is that, when we are writing to the shared storage, we are not directly writing to it. To be fault tolerant and avoid problems, first we write to a temporary file, and then we do an atomic rename operation. Another Detail When reporting back to the coordinator that a task is finished, we also need to include the host name and PID, because the coordinator needs to be sure that the output comes from someone that is currently responsible for the job, not someone whe was responsible but got timed out, and then came back live again. I made this mistake before, and it is hard to debug, because it may seem like we don’t need a worker PID in the reply struct. Without this, the MapReduce will fail the Crash unit test. Distributed applications are very hard to debug!!! Each intermediate output is hashed to nReduce partitions, for later consumption of the reduce RPC. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152func doMap(mapf func(string, string) []KeyValue, filename string, mapID int, nReduce int) { file, err := os.Open(filename) if err != nil { log.Fatalf(&quot;cannot open %v&quot;, filename) } content, err := ioutil.ReadAll(file) if err != nil { log.Fatalf(&quot;cannot read %v&quot;, filename) } file.Close() kva := mapf(filename, string(content)) writeMapOutput(kva, mapID, nReduce)}func reportMapDone(TaskId int) { args := ReportTaskDoneArgs{TaskType: MapTask, TaskId: TaskId, WorkerID: os.Getpid()} reply := ReportTaskDoneReply{} call(&quot;Coordinator.ReportTaskDone&quot;, &amp;args, &amp;reply)}func writeMapOutput(kva []KeyValue, mapID int, nReduce int) { tempFiles := make([]*os.File, nReduce) encoders := make([]*json.Encoder, nReduce) for i := 0; i &lt; nReduce; i++ { tempFile, err := ioutil.TempFile(TempDir, &quot;intermediate-&quot;) if err != nil { log.Fatalf(&quot;cannot create temp file&quot;) } tempFiles[i] = tempFile encoders[i] = json.NewEncoder(tempFiles[i]) } for _, kv := range kva { // fmt.Println(nReduce) reduceID := ihash(kv.Key) % nReduce err := encoders[reduceID].Encode(&amp;kv) if err != nil { log.Fatalf(&quot;cannot encode kv&quot;) } if err != nil { log.Fatalf(&quot;cannot encode kv&quot;) } } for i, tempFile := range tempFiles { tempFile.Close() filename := fmt.Sprintf(&quot;%v/mr-%d-%d&quot;, TempDir, mapID, i) os.Rename(tempFile.Name(), filename) }} Similar procedures happen with the Reduce part of the worker code: get assigned a job read in the correspond partition based on RPC reply do the reduce call write the file back, do atomic rename to be fault tolerant 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152func reportReduceDone(TaskId int) { args := ReportTaskDoneArgs{TaskType: ReduceTask, TaskId: TaskId, WorkerID: os.Getpid()} reply := ReportTaskDoneReply{} call(&quot;Coordinator.ReportTaskDone&quot;, &amp;args, &amp;reply)}func doReduce(reducef func(string, []string) string, reduceID int) { // println(&quot;do reduce called once&quot;) // 1. Read all the intermediate files files, err := filepath.Glob(fmt.Sprintf(&quot;%v/mr-*-%d&quot;, TempDir, reduceID)) if err != nil { log.Fatalf(&quot;cannot read temp files&quot;) } // 2. Group the files by key intermediate := make(map[string][]string) for _, filepath := range files { file, err := os.Open(filepath) if err != nil { log.Fatalf(&quot;cannot open temp file&quot;) } dec := json.NewDecoder(file) for { var kv KeyValue err := dec.Decode(&amp;kv) if err != nil { break } intermediate[kv.Key] = append(intermediate[kv.Key], kv.Value) } file.Close() } // 3. Call reducef on each group outputFile, err := ioutil.TempFile(TempDir, &quot;mr-out-&quot;) if err != nil { log.Fatalf(&quot;cannot create temp file&quot;) } defer outputFile.Close() for key, values := range intermediate { output := reducef(key, values) fmt.Fprintf(outputFile, &quot;%v %v\\n&quot;, key, output) } // 4. Write the output to a file finalFilename := fmt.Sprintf(&quot;mr-out-%d&quot;, reduceID) os.Rename(outputFile.Name(), finalFilename)} Implementation of the CoordinatorWhen a request for task comes to the coordinator, we need to assign tasks: Now that we have shared data structures in the coordinator, to avoid race condition, we need extensive locking. Just lock everything that is shared, and you will be fine. The idea is simple: when a request comes in, assign it either a map task or a reduce task, change the task status, and the worker assigned this task (for timeout operations). Also start a go routine waitTask to check for timeout. If timeout happens, then a process is no longer responsible for a certain task. Even if we get result back from the timed out node, we will discard the result (we need to do extrac check of PID in the result we get back). 123456789101112131415161718192021222324252627282930313233343536373839func (c *Coordinator) RequestTask(args *RequestTaskArgs, reply *RequestTaskReply) error { c.mu.Lock() defer c.mu.Unlock() if c.stage == ExitStage { reply.TaskType = ExitTask return nil } if c.stage == MapStage { for i, task := range c.mapTasks { if task.State == NotStarted { c.mapTasks[i].State = Running c.mapTasks[i].StartTime = time.Now() c.mapTasks[i].WorkerID = args.WorkerID reply.TaskType = MapTask reply.File = task.File reply.TaskId = task.TaskId // fmt.Printf(&quot;Assign map task %v to worker %v, filename:%s\\n&quot;, task.TaskId, args.WorkerID, reply.File) go c.waitTask(&amp;c.mapTasks[i]) return nil } } } if c.stage == ReduceStage { for i, task := range c.reduceTasks { if task.State == NotStarted { c.reduceTasks[i].State = Running c.reduceTasks[i].StartTime = time.Now() c.reduceTasks[i].WorkerID = args.WorkerID reply.TaskType = ReduceTask reply.TaskId = task.TaskId reply.File = task.File go c.waitTask(&amp;c.reduceTasks[i]) return nil } } } reply.TaskType = NoTask return nil} Since we are talking about timeout, here is the implementation: 12345678910111213141516func (c *Coordinator) waitTask(task *Task) { time.Sleep(10 * time.Second) c.mu.Lock() defer c.mu.Unlock() if task.State == Running { if task.Type == MapTask { fmt.Printf(&quot;Map task %v timeout, reassigning\\n&quot;, task.TaskId) c.mapTasks[task.TaskId].State = NotStarted c.mapTasks[task.TaskId].WorkerID = -1 } else { fmt.Printf(&quot;Reduce task %v timeout, reassigning\\n&quot;, task.TaskId) c.reduceTasks[task.TaskId].State = NotStarted c.reduceTasks[task.TaskId].WorkerID = -1 } }} If a timeout happens, which we monitor with a go routine, the state of the task, as well its worker, are changed accordingly. Note how we protect shared data structure with a lock. If we receive a message, saying that a task has been done, we need to do the following: Check the task type, state of the task, and whether the result comes back from someone who is actually responsible for the job. Change the task status If all tasks (map and reduce) have been finished, get back to the workers, telling them that we have done all the jobs. Translate the logic into code, and we get: 1234567891011121314151617181920212223242526272829func (c *Coordinator) ReportTaskDone(args *ReportTaskDoneArgs, reply *ReportTaskDoneReply) error { c.mu.Lock() defer c.mu.Unlock() if args.TaskType == MapTask { if c.mapTasks[args.TaskId].State == Running &amp;&amp; c.mapTasks[args.TaskId].WorkerID != -1 &amp;&amp; c.mapTasks[args.TaskId].WorkerID == args.WorkerID { c.mapTasks[args.TaskId].State = Finished c.mapTasks[args.TaskId].WorkerID = -1 c.nMap -= 1 fmt.Printf(&quot;Map task %v finished, nMap: %v, nReduce: %v\\n&quot;, args.TaskId, c.nMap, c.nReduce) } } else if args.TaskType == ReduceTask { if c.reduceTasks[args.TaskId].State == Running &amp;&amp; c.reduceTasks[args.TaskId].WorkerID != -1 &amp;&amp; c.reduceTasks[args.TaskId].WorkerID == args.WorkerID { c.reduceTasks[args.TaskId].State = Finished c.reduceTasks[args.TaskId].WorkerID = -1 c.nReduce -= 1 fmt.Printf(&quot;Reduce task %v finished, nMap: %v, nReduce: %v\\n&quot;, args.TaskId, c.nMap, c.nReduce) } } if c.nMap == 0 &amp;&amp; c.nReduce == 0 { // fmt.Printf(&quot;All tasks finished\\n&quot;) c.stage = ExitStage reply.CanExit = true } else if c.nMap == 0 { c.stage = ReduceStage reply.CanExit = false } return nil} There are some additional details of the code, that I haven’t covered, but the main idea is here. For details, refer back to my source code: https://github.com/PeterYaoNYU/mit-distributed-sys.","link":"/2024/01/09/Implementing-a-MapReduce-Framework-with-Golang-from-scratch/"},{"title":"CMU15-213 Attack Lab","text":"It’s been a while since I wrote posts about CMU’s renowned system course 15-213. Last month, I was primarily devoted to my research on SmartNICs and ML for failure detection, and traveling. Let’s begin phase by phase. Logistics The writeup of this lab can be found here (the CS:APP website). You can download it from this blog as well. The target file can be downloaded from my website as well. Open that using linux tar, or you may change the permissions of the file. target1Download According to my experience, this lab does not work on virtual machines. Bare metal Ubuntu is preferred. I use NYU server instead. Not working on my multi-tenant cloud server Working on NYU bare metal Ubuntu20 server Non-CMU student, when running the code, should add a -q flag, so that the program will not try to contact the grading service and then failed. Phase 1: Simple Buffer Overflow Attack Phase 1 is a very simple buffer overflow attack, and its main idea was went through during the lecture. First use objdump -d to get the disassembled file, can be .txt or .asm. Then check the disas file. Use Vim to search for , we find the main logic of phase 1. It calls and then returns. We want to change the return address so that when the execution returns from , it will be redirected to the function. function has an address of 0x00 00 00 00 00 40 17 c0, and we want to jump to it. To inject the malicious return address, we first need to know how much buffer the function has allocated. I suggest that you take GDB as your most loyal friend. Ok, so the allocated 0x28 bytes, which in decimal is 40 bytes. So we first need to fill the 40 bytes buffer with random input, and then the address of the desired function. Remember that the function fills the stack from the smaller address to the bigger one. So it starts filling from the lower right corner to the upper left corner. However, when the program is reading the return address, it reads from the bigger address to the smaller one (reverse direction). With that being said, the injection string could look something like this: 12345678910111200 00 00 0000 00 00 0000 00 00 0000 00 00 0000 00 00 0000 00 00 0000 00 00 0000 00 00 0000 00 00 0000 00 00 00c0 17 40 0000 00 00 00 Try it, works as expected. Phase 2: Code injection This level is a lot more interesting, I have got to say. The biggest challenge for me is to recall the fact that stack grows downwards (from bigger virtual addresses to smaller ones), while the binary code is executed bottom up (from smaller virtual addresses to bigger ones). So remember that in phase 1 we need to reverse the order of out input so that the malicious return address is in the correct order? In this phase, now that we are directly injecting malicious code, we do not need to reverse the order of the code, since they are executed bottom up, in accordance with the order that gets the input from the user, which is also bottom up. However, we still need to reverse the order of the intended virtual addresses, since the input order is the opposite of the way return address is read by the operating system. Forgive me for speaking too much without giving you an idea what we are doing here. In this level, we need to redirect the return address of the program to but at the same time change the first parameter register %rdi to have value in our cookie.txt, which in our case has the value: Sounds challenging, right? The basic idea is that: first we need to change the return address after the procedure to somewhere on the stack (in this question, stack execution protection is disabled), that somewhere should be the place where we input our malicious code, which is the 40 bytes buffer of the function. For convenience, I will just set the return address to the bottom of the stack when the is called, namely the start of the 40 bytes buffer. Then we need to think about what code we would like to put in the stack we were given. I propose something like this, in assembly of course: 123mov $0x5561dc98, %rdipushq $0x000000004017ecret The first line puts the cookie into the register that holds the parameter value for procedure . The second line push a return address to the stack, and pushq command will also automatically decrement the stack pointer by 8, so that when we execute ret command in the third line, the stack pointer will increment by 8 automatically, and pop the return address out. This 0x4017ec address points to the procedure, which can be found out here: The last piece of this puzzle is, what should the return address of the function be changed to? We want to change it to the beginning of our malicious injected code, which we inject starting at the lowest address of the 40 byte buffer. The answer is self-evident, we need to change the return address to the lowest address of the buffer, and the code will be then executed from bottom up. So what is this lowest address? I suggest GDB again, your most faithful friend with Linux. The answer is here, 0x5561dc78! One last step before putting everything together. What is the binary representation of the assembly that we are injecting? To find out, first compile this assembly, and then objdump -d the output to find out. Putting everything together, here is what we should input this is indeed a valid answer for level 2 of the lab. Phase 3: Advanced Code Injection This phase is quite formidable, I have got to admit. Let’s first check out the requirement of the question, it gives us a lot of useful hints. The code snippet is not entirely easy to understand, because it does seem a little bit whimsical. If you were able to break down the requirement, here is what we need to do: jump to , which is at address 0x4018fa of the virtual address space pass the address of the ASCII representation of our cookie to register %rdi, which serves as a parameter when we call the procedure . Figure out a safe place within the stack to store the ASCII representation of our cookie, because some portion of the stack may be overwritten by the the code from It is observable that we first need to figure out (3), i.e. a safe place that will not be overwritten, then figure out the code we inject to the buffer. So what is the ASCII representation of the cookie, which for us is 0x59b997fa? How many bytes of space do we need to store the ASCII representation of it? It seems that we need 8 bytes of space, and the ASCII code is 35 39 62 39 39 37 66 61. So which place is safe to store these 8 bytes? In other words, which part of the stack will be overwritten when we call ? GDB will tell us. First, try this input, then check how much of the 11111…1111 buffer space is changed by hexmatch in GDB. The return address is changed by buffer overflow to so that we can observe the behavior of . 12345678# convert hex to raw hex./hex2raw &lt; p3\\_test.txt &gt; p3\\_test\\_raw.txt# GDB COMMANDgdb --args ./ctarget -qb testrun -q &lt; p3\\_test\\_raw.txt# inspect the first 80 bytes starting at a certain address, in hexx/20x 0x5561dc78 now that we are in , make a breakpoint before and after to see how much of the buffer has been changed. 12(gdb) b \\*0x040190b(gdb) b \\*0x0401916 this is the buffer layout before calling this is the buffer layout after calling we can see that all 40 bytes have been overwritten. So we have to buffer overflow more, and store the address of the ASCII code at someplace after. Address starting at 0x5561dca8 seems unchanged after calling , and is thus a valid candidate. So we want to overflow more than the typical 48 bytes. We want at least 56 bytes, and the last 8 bytes are for the ASCII. Then we need to translate the code using the same technique: write the code, gcc -c, objdump -d You see that we store the address of the ASCII to $rdi, change the return address to and then return. We put the code at the beginning of the buffer, so the return address of should also be changed to 0x5561dc78 Putting everything together, here is the injection code: 123456789101112131448 c7 c7 a8dc 61 55 68fa 18 40 00c3 00 00 0000 00 00 0000 00 00 0000 00 00 0000 00 00 0000 00 00 0000 00 00 0078 dc 61 5500 00 00 0035 39 62 3939 37 66 61 test it, it is indeed the answer. Phase 4: Return-Oriented Attacks This phase is quite easy, takes around 20 minutes to solve (the previous phase takes me hours…) The key idea is to understand how to use return-oriented programming to inject malicious code. I think that the lab write-up did a pretty decent job, so let me just quote here. The main difficulty then is to find the appropriate code segments and piece them together. here is the requirement for this phase. If you are logical enough, here is the stuff that we need to do: use popq instruction to put the cookie to %rdi then jump to the procedure As hinted by the author, here we only use popq and movq. Two gadgets are enough. Now let us take a look at the gadgets available! We can only use the first 8 gadgets, from the &lt;start_farm&gt; to the &lt;mid_farm&gt;. Apparently, we need a popq to pop the cookie to a certain register, so we are looking for anything from 58 to 5f. You can choose either &lt;getval_280&gt; or &lt;addval_219&gt;, which contains 1258 90 c3 // popq %rax Note that there is no 5f in the code snippet farm, so we cannot pop directly to %rdi. We can however, later move the content from %rax to %rdi. So we are looking for 48 89 c7. &lt;setval_426&gt; provide the segment for that. I choose &lt;getval_280&gt; and &lt;setval_426&gt;, the first at 0x4019cc, and the latter at 0x4019c5. The function is at address 0x4017ec. Putting everything together, we now want the stack to have the following layout, the code bottom being the top of the stack: 12345678900 00 00 0000 40 17 ec // touch2 address00 00 00 0000 40 19 c5 // mov from %rax to %rdi00 00 00 0059 b9 97 fa // my cookie00 00 00 0000 40 19 cc // pop to %rax...... 40 bytes random (the original &lt;getbuf&gt; buffer) in order to achieve that layout, we want out input to be Test it out, and it is indeed the answer. Phase5","link":"/2023/07/10/cmu15-213-attack-lab/"},{"title":"Bomb Lab CMU 15-213","text":"May 18th, 2023. I have just finished all my final yesterday. Farewell my sophomore year! After playing the new Zelda: Tears of the Kingdom for the whole evening, which was released just a few days ago (and without any doubt, the best game ever made in human history), I decided to do something a little bit more meaningful and fulfilling. I started on the lab assignments of 15-213 when I was still a very naive and stupid freshman (I’ve got to admit that I am kind of stupid in the freshman year…). Back then I don’t know anything about computer systems. It is a terrible terrible mistake to start Intro to Computer Sys when you don’t have a clue what C and POSIX and OS is. The labs will just gradually suck out the false confidence that you got from the undemanding NYU curriculum and the all too high level Python. Apparently, this course is by no means, as its name suggests, an intro one. We’ve got to learn to respect CMU. After being through some pretty traumatic experience at Operating Systems and Distributed Systems classes, I decided that I am tortured enough to begin again on the lab assignment of CS:APP. Being a seasoned and perhaps too experienced C programmer, I think I can easily handle an introductory undergraduate course on Systems. (Or can I? Let’s find out!) I will skip Data Lab (the first lab) at least for now, because it’s not a particularly interesting one. I will come back to it when I have the time to do so. Bomb lab should be the fun part. Let’s begin with that. If you are a student enrolled in CS15-213 at CMU, DON’T MOVE ON!!! Keep in mind that this would constitute a violation of academic integrity. This material is intended to give self-study students some intuition and help when they are stuck and alone with no one to seek help from. Phase 0: Preparation You can either download the source code from the CS:APP website, or from the mirror on this site. bombDownload I find this GDB document particularly helpful. It’s clear and detailed. gdbnotes-x86-64Download Some commands that are not in the document, but I personally use a lot, are: 12&gt; layout src&gt; layout asm This way the assembly / code are juxtaposed with the output in a way that is more convenient to read. Phase 1: Starting with the Simple One After downloading the bomb, first check out the source file to get a rough idea of what this program is doing. However the source file alone is not very informative. Basically for every phase, the program will read an input, and if the input is not correct, it will trigger a signal to set off the alarm. Otherwise that phase is defused. The real hint hides within the object file. You may way to first find out what is in the symbol table, by using: 1&gt; objdump -t bomb Some interesting tags include: phase 1…6, sigalrm_handler, phase_defused… Oh look, there is even something called a secret phase. Is that a bonus? Still not very informative, but at least we know where we can set out breakpoints. Breaking at phase_1, and run the program, you are required to input a string, as was indicated when we examine the source code. Since I am proud of my own culture and heritage, I will just put here China. (remember that this is a 5 byte string, it is an important hint later). Moving on, let’s examine what is in the assembly of phase 1. seems like it moves 0x402400 to %esi. An easy guess would be that 0x402400 is a memory address, since we are talking about string here. We cannot put a string in a register, only the address of it. It is worth noting that %esi is the second argument register. So it is clear that we are passing information into a function. Phase_1+9 tells us that this function is called strings not equal. But what about %rdi? After all %rdi is the first argument register, and if we use %rsi, that means that %rdi is also used. That is a valid question, and it seems to me that %rdi stores what we input initially, in the initialize_bomb() function call. It will be verified later. Remember that before, in phase 1, a function called strings_not_equal is called. Now let’s step into it, and examine what it does. The two arguments are each passed first into a function called string_length. It’s not too hard to guess it’s meaning from the name. Apparently, we will jump to strings_not_squal+99 if the length of the two arguments differ. That line will return 1 to phase_1 function, and phase_1, after seeing 1 in %rax, will set off the bomb. BOOM! Checking the register value, we found that %r12d has value 5, which happens to be the length of the word “China”. What a wonderful coincidence! %rax has value 52, so ah, it seems like the answer string has length 52. We are getting very close to the answer. Remember how we stored the address of the correct answer in %rsi, and thar address is 0x402400. All that is left to do is to examine what is store at that address, and exactly 52 words from that, nothing more, nothing less. Use the command in GDB to get what you want: 1&gt; x/52s 0x402400 The answer is in the picture. Honestly, I didn’t expect it to be this political LOL. Phase 2: Let’s Talk About LOOPS! Phase two is an easy one, took me less than 15 minutes to solve. It is pretty intuitive, given that I got stuck and trained in phase 1. As always, let’s first set a breakpoint at phase_2, and then check what is in the assembly. What I find most intuitive to do is to unfold the loop functions in a series of commands, so that we don’t have to think too much about loop, and that is exactly what I will do. First, the compiler saves some callee saved registers that may be altered, then it decrements the stack pointer by 0x28 (pay attention, we are talking about hex here, you will be seriously wrong if you think about decimal, like I once did). Then the function calls a function named &lt;read_six_numbers&gt;. I don’t even bother to step into that particular function, because its purpose is already all too clear from the name itself. It just read 6 numbers, and it seems that this time, we need to input 6 numbers as the answer. Six numbers, that is really a lot. Apparently, the compiler will not use the register to save these 6 numbers, what it will do is to store the 6 numbers on the stack, starting from the stack pointer %rsp obviously. The phase_2 assembly from the previous picture is not complete, with this pic, it is complete now. We definitely want to jump at line phase_2+18, otherwise the bomb will explode! To jump, we must make sure that the number in *(%rsp) is 0x1, so the first number we input should be 1. Now that we have jumped to line phase_2+52, %rbx = 4 + %rsp (we are not yet dereferencing here), %rbp = 18+%rsp. And then we jump back to line phase_2 + 27. Starting from line phase_2+27, %eax = * (%rbx-4) = * (%rsp) (we are dereferencing here), %eax = 2 * %eax, since we want to jump at line phase_2 + 34 to avoid triggering the bomb at line 36, %eax should be equal to *(%rbx), in other words, *(4+rsp) = 2 * (*%rsp). So what should be the second element in the 6 int array we input then? Apparently 2!!! Jumping to line 41, %rbx = %rbx + 4 = %rsp + 8. If %rbx != %rsp + 24, then we loop back to line 27, where we must make sure that the latter element is twice as big as the previous element. However, if we are lucky enough to have %rbx = %rsp + 24, which will eventually happen after 6 iterations, we will just go to line 64, restore the stack, and then return. With that said, it is pretty apparent that the sequence of number should be 1 2 4 8 16 32, since we are inputting 6 numbers as specified. We tried that out, it is indeed the solution!!!!!!! So exciting!!!!!!!! Phase 3: Jumping Around! Today is May, 19th, 2023. After a long hard day working on the impossible research project, I finally had some time to myself. (Maybe I will write a post about that project a little bit later, I do believe that it is a very meaningful and truly inaugurating project, but it looks VERY formidable). Phase 3 of the bomb lab is a lot more difficult than the previous two, I have got to admit. I have to spend around an hour to solve this problem. As always, first we will set a break point at phase_3, and run the program as usual. You can first input anything, as long as we quit GDB before the bomb is set off, we are fine. if you do that, here should be what you see: Stopping right before phase_3 begins. I am utterly curious what is store at address 0x4025cf, since it is passed as an argument to the sscanf function at line 24. So I examine what was in that address. As it shows, it stores a string, whose content is two place holders for decimal values. (Why do I print it as String? Well, the sscanf function kind of gives you a hint. sscanf function should take as input a string (out input, and a string representing the place holders like %d %d). This belief is collaborated by the fact the at line phase_3 + 19, the program requires that the return value of sscanf should be bigger than 0, otherwise, the bomb will explode. The return value of sscanf should be the number of integers parsed successfully. Though trial and failure, you will indeed find that, no matter how many numbers you try to input, the result will still be 2 at most, since we only have 2 place holders for integers. With that knowledge in mind, we should adjust our input accordingly, so that we can at least survive past line 34. I will just input 6 8. They are all lucky numbers in China! Since we are moving on to deal with the content in the stack, I think that it was high time that we examine what is now in the stack. We find that 6 and 8 that we input before is now in the stack, thanks to the sscanf function. What are the first 2 bytes, I really don’t care. I just need to know where my inputs are stored. So apparently, we are jumping at line phase_3 + 50, to a mysterious place based on the stuff in *($rsp+8), which happens to be our first input number. There are several lines doing similar things, storing a number in %rax, and jump to line 123. At line 123, we want to make sure that *(12+%rsp)==%eax, whatever was put into %rax at previous steps. Note that 12+%rsp is the place where we store our second input number!!! Now things are clearing up!!!!!!!!!!!! We jump to a certain line based on out first input, the program will then put a certain number into %rax, we just need to make sure that our second input is the same as the number put into that register!!!!!!!!!! GOOD!!!!!!!!!!!!!!! For simplicity, I will make the first number 0. There is no reason to calculate which line we jumps to by hand, use GDB’s nexti to find out where we jump to, and then adjust the second input number accordingly. So we find that with 0 we jump to line 57, which puts 0xcf into %rax. 0xcf is 207 in decimal. Try 0 207 as a tentative answer, and phase 3 will be defused successfully! As I alluded to, you can also try 1 as the first input, step with GDB, and you will find that the second input should be decimal 311. 1 311 is also a valid answer! You can try more, but I will stop here. Hoped that you enjoyed it so far!!! Phase 4: Function Calls Today is May 21st, 2023. I am trying to finish one phase per day of this lab. This is a little ambitious, because I play too hard during the summer holiday. Luckily, phase 4 of the lab is not a difficult one, as I get more experience with assembly along the way. It took me around half an hour to solve this problem. As always, let’s set a breakpoint at phase_4 first, and then step through the assembly. Here is what we get when we inspect phase_4 of the code. Okay, apparently, we are using sscanf to turn our string input into numbers, or something else. The question that remains is how many numbers we should input? We could find this out by inspecting the second argument of sscanf, which is what is stored in %esi: 0x4025cf. This is quite similar to what we did in phase_3, and because I still remembered that from two days ago, this step is quite intuitive. It is expecting a string of the format “%d %d”. So by inspecting the format stored at 0x4025cf, we should input two numbers. Now the central question becomes, which two numbers should we input? To answer that, we need to inspect the assembly further. First we allocate on the stack 18 bytes. %rcx = 12 + %rsp. %rdx = 8 + %rsp. Again, these two registers are arguments passed into the sscanf function. This alludes to the fact that the two numbers that we input to the program are each stored in 8+%rsp and 12+%rsp. This fact can be checked by inputing two random numbers and then inspect the stack, which I will omit here since it has been demonstrated previously. I really cannot decipher what ws in the first 8 bytes starting at %rsp, nor do I really care about it. Then, it is apparent that if we want to avoid triggering the bomb, then we should really make sure that we jump at line 39. In order to jump, we have to make sure that the first input is smaller than or equal to the number 0xe, which is 14 in decimal. Line 69 also requires that the second input, which is stored at 0xc(%rsp), should be equal to 0. It is calling a procedure called , and the arguments are: %rdx=14, %rsi=0, %rdi=first input. Let’s move on to inspect what is going on in , shall we? Stepping into Now we are stepping into func4, %rax = %rdx = 14, %eax = %eax - %esi = 14 - 0 = 14, %ecx = 14. Shift %ecx right by 31 bits, and store the result back in %ecx, so %ecx should be the sign bit of 14, which is 0. %eax = %eax + %ecx = %eax + 0 = %eax = 14. %eax shift arithmetic right by 1 bit, which makes %eax 7 (divide by 2). At line 17, %ecx = %rax + 1 * %rsi = 7 + 1 * 0 = 7. We don’t really want to call recursively at line 27, so %edi had better be less than or equal to %ecx, with %edi being the first input and %ecx being 7. Assume that we jumped successfully to line 36, which moves 0 to %eax (this is what we want, since we want at line phase_4 + 65, that the return value of func4 being 0, to avoid setting the bomb off!!!). Then we really want %edi &gt;= %ecx, to avoid the recursive calls to func4. Remember that previously, we want %edi &lt;= %ecx, so these two should really be equal, which gives us the right first input: 7. Just to give you the full picture what is doing… Recall that I said that the second input should be 0, and we need two numbers exactly. The answer is here: 7 0 There may be more than 1 answer, but I will stop here. And we are successful, it is indeed the answer!!! Phase 5: Cracking ASCII Code Hey guys, it’s midnight on May 21, 2023, 23:53. I have just finished phase 5 of the bomb lab (two phases in one night, because it is really super FUN!!!!!!). I am writing overnight in case I forget how to solve this problem when I wake up in the morning…. And also partly because I am so excited right now LOL. This phase is worth extra credits, because it is supposed to be more difficult. However, I found the difficulty very acceptable, and it took me around 30 minutes to solve this problem. So don’t be terrified by the apparent complexity of this problem. If you have been following along, you have what it takes to solve this problem very easily. As usual, let’s set a breakpoint at phase_5, and then examine the assembly via GDB. So it allocate for the stack a space of 32 bytes, but the last 8 byte of the stack is protected by the canary to protect the process from stack overflow attack (this is a GCC default). So really the actual amount of space we can use on the stack is 24 bytes. Then we use xor to force %eax to become 0, and then call the procedure &lt;string_length&gt;. We want to make sure that the return value in %rax is 6, otherwise the bomb will be triggered. So apparently the length of our input should be of a string of length 6, and we will jump to line 112. Line phase_5 + 112 just clears the content in %eax, and then jump back to line 41, which, as we will see, is a loop that serves as the main logic. Moving back to line 41… It looks that we are in a do-while loop. Let’s examine this part of the ASM closely. It first stores the character at address (%rbx + 1 * %rax) = %rbx = input string starting address, to the register %ecx. It moves the lowest byte of %ecx to address (%rsp). It then moves the content at address (%rsp) to register %rdx, and AND with 0xf the last 4 bits. So now what is left in %rdx is the last four bits of the first character of our input. Now we are at line phase_5 + 55, which is moving the byte at address 0x4024b0 + %rdx to register %edx, and moves the lowest byte to address %rsp + 1 * %rax + 16, and then reenter the loop until all 6 characters have been iterated. In other words, the i th byte that we load to the upper part of the stack frame (starting at the 16th byte and should not exceed the 24th byte because of the stack protector of GCC) depends on the last 4 bits of the ith character of our input stirng. Then we should make sure that the new string at the upper part of the stack frame should be equal to the string stored at address 0x40245e, both address are passed as arguments into a function called &lt;strings_not_equal&gt;. If they are the same, then the bomb will be defused. So let’s first find out which string we are trying to match here. So apparently we are trying to construct a string called “flyers”. And we are selecting from a reserve of characters, starting at address 0x4024b0 from line phase_5 + 55. So we have”maduiersnfotvbyl” to choose from, which contains all characters in the string “flyers”. Also note that we only have 16 characters here, which is the maximum number of choices that can be represented with 4 bits, since we are only using the last 4 bits of each character of our input as offset into this character reserve. This cannot be a coincidence, we are in the right place bro. So we want our offset at %edx to be 9, 15, 14, 5, 6, 7 to get “flyers”, which translate into binary “1001 1111 1110 0101 0110 0111”, and all we need to do is to find 6 characters whose lower 4 bits are exactly that. Checking the ASCII table, this string could be, but not necessarily, “9 ? &gt; 5 6 7“ since the lowest 4 bits matches. We try this, and this is indeed the answer! Not too hard, right? Told you Phase 6: Linked List and Sorting The last phase of the bomb is significantly more complex than previous phases. It makes heavy use of pointers and array, which makes this procedure call a lot more complex. I will try my best to explain what is going on. Let’s give out the answer first, because, why not? We input 4 3 2 1 6 5, and then see what will happen. The first part of the code, from the first line to &lt;phase_6+93&gt;, is doing these: first read in 6 numbers from the standard input, put them at the beginning of the stack frame (as was done usually, this can be verified by printing the stack), check that all numbers are equal to or less then 6 (line phase_6+52, 56), and then check, using a for loop, that every number after is different from itself. This can be roughly reverse engineered to the following code: 123456789101112read_six_numbers from stdin;store them on the stack, starting from %rsp; (use arr to represent the six number array)for (int i = 0; i &lt; 6; i++){ if (arr[i] &gt; 6) { ABORT; } for (int j = i; j &lt; 6; j++) { if (arr[j] == arr[i]) { ABORT;}}} The second part of the assembly, from &lt;phase_6+95&gt; to &lt;phase_6+121&gt;, is subtracting each number from 7, and store the result of the subtraction at the original stack position. This can be translated into the following pseudo code. 123for (int i = 0; i &lt; 6; i++){ arr[i] = 7 - arr[i];} The third part of the code puts address of each node to the stack frame, starting at position rsp+32. The most important address to understand is 0x6032d0. Print it and you will discover that the memory that this address points to store a linked list, though all its nodes are in a contiguous memory. Printing the memory at 0x6032d0, something that I did not notice the first time is that the author gives you hint that this is a linked list data structure. Notice the yellow part of the disassembly actually says “node1”. The first field of each node seems to store the element, the second field is the index, the third field is the pointer to the next node, and the fourth field is what we call alignment, which speed up the memory fetch of a struct. In hex, makes the address that the second word of each node points to clearer. The linked list is actually contiguous in memory here. It takes some time to get a grasp of what the assembly is doing here. The rough idea is that it is storing the address of each node in the stack, and the sequence is in accordance of the 6 numbers we input (remember that we take 7 - i for each i we input, so the actual sequence is reversed. In other words, if the first number we input is 2, then the 3rd node will be stored in the 5th place of the array on the stack). If we take a breakpoint after all this madness has ended &lt;at phase_6 + 183&gt;, and then print out the stack memory, we will find that this is indeed the case. After all madness ended, this is the memory layout. Starting at the third line, every word stores the starting address of the node. Nodes are put in a sequence that is relevant with our input to the program. After executing through &lt;phase_6+183&gt; to &lt;phase_6+220&gt; From line phase_6+183 to phase_6+220, the code does not do much. As we can tell from the above picture, which is the result of the execution of this part of the code, it just make the singly linked list a ring, pointing from the tail to the head. The last part of the code checks that each node stored in the array on the stack has a bigger element than the next node (here by next I don’t mean the next node pointer, but rather the sequence we input). If it is bigger, than we can defuse the bomb successfully. Otherwise, the bomb goes off. It is okay if you cannot decipher every line of the assembly, just focus on the result of each part of the code, and try to guess (or in a fancier term, reverse engineer) what is going on in each part. In all previous phases, I can understand each line of the disassembly with ease, but the last phase is different. I learned to focus on the result, instead of trying to decipher every line of the disassembly, because there are just too many lines. So apparently, we kind of get the rough idea, after dividing the code into blocks, and then interpret the result of the execution of each code block, that we are sorting a linked list here, and the number we input reflects the order of the element of nodes. In the last part, we want to make sure that on the stack, nodes are put in decreasing order: 3 4 5 6 1 2. But since we take each number off 7 previously, the sequence we give to the program should be 4 3 2 1 6 5. Put 4 3 2 1 6 5 to sol.txt, and then run the program. Test it, and indeed, this is the result. We have defused the bomb successfully!!! This concludes this lab assignment.","link":"/2023/05/18/bomb-lab-cmu-15-213/"},{"title":"Higher-order Functions","text":"A higher order function is technically any function that takes another function as an argument.","link":"/2023/02/14/higher-order-functions/"},{"title":"Paper Reading - CS Model - Some constraints and tradeoffs in the design of network communications","text":"client-server-issues-Akkoyunlu-et-al-75Download Name: Yuncheng Yao (Peter) Reference: E. A. Akkoyunlu, K. Ekanadham, and R. V. Huber. 1975. Some constraints and tradeoffs in the design of network communications. In Proceedings of the fifth ACM symposium on Operating systems principles (SOSP ‘75). Association for Computing Machinery, New York, NY, USA, 67–74. DOI:https://doi.org/10.1145/800213.806523 The challenge that the authors address is how to incorporate many desirable but sometimes conflicting features into a client server model, by making necessary tradeoffs to solve the incompatibility. Some reasonable assumptions about the system are made. The clients and servers communicate via messages and ports; the most complex failure model is the timing failure, and failures may be silent; the system is asynchronous in terms of communication and computation; there is no mysterious system buffering as in MPI; failure intervals are long compared to the transaction time. The author also ruled out some unreasonable assumptions. It is not realistic to assume that 1)the network is reliable; 2)the topology is connected all the time; and 3) failures can be detected immediately. The features that the authors want to include in theirs systems are: Status. Because status information cannot be provided elsewhere if it is not provided in the IPCM; Time-out. Because we don’t want to block the whole process forever just because of a single undelivered message; Insertion property. This provides maximum abstraction to the users by supplying them with limited communication primitives; Well known ports. It exposes frequently used resources like HTTP, compiling, FTP… ; Partial transfer to deal with different buffer sizes; The authors identify some inevitable incompatibility among those desirable features and proposed possible solutions to have them all by making acceptable compromises. The conflict between the incomplete connectedness of the topology (eg. network partition) and providing complete status. Accurate status messages may be blocked by a partition. The conflict between time-outs and complete status. Even with the strong assumption that the network is reliable, because of the asynchronous nature of our communication model, a status message may not arrive before the time-out, and we cannot be sure whether the message got delivered and accepted (but is still being processed by the server), got delivered and rejected, or that the status information is sent but not yet received. The conflict between time-outs and insertion property. Similar to Conflict 2, it is impossible to be sure about the exact outcome of the transaction with time-outs, a situation that cannot happen had these two processes been directly connected on a centralized system, and this uncertainty violates the insertion property. The solution to the first 3 conflicts is to provide the same ambiguous status information in many situations where we are not certain about the exact correct status . Whether the message is never delivered successfully, or the delivery to the server is complete but status is not sent in time, or that the status is sent but not received by the client in time, it is the same ambiguous status provided to the client. The tradeoff that we are making is that we are unable to provide complete status, but we will be able to provide some status. The conflict between the strong insertion property and the varying buffer sizes of different processes. Enforcing a universal buffer size is restricting, and violates insertion property by exposing communication details. Solution: Allow partial transfers. The conflict among partial transfer, time-outs and insertion property. The RECEIVE request may time out before a complete message is transferred, and by telling the server process about the data existing in the buffer, we expose ugly communication details and violate insertion property; if we don’t tell the server process about the incomplete message, the message gets lost. Solution: Adopt a weaker insertion property and allow buffer sizes to be exposed when necessary. The conflict between well-known ports, partial transfer and time-outs. Time-outs are necessary here, otherwise the well-known port may be blocked by a super slow message. New messages arriving after the original SEND request has timed out raises data consistency issues. Solution: Ban partial transfer with well-known ports. Longer messages sent to the well-known process must use separate connections which are set up after the initial short message sent to the well-known port, which potentially use a layer of buffer processes, or communicate via another port. The conflict between many ports processes and partial transfers. With or without a separate buffer for each port, once a complete message arrives while there is an incomplete one, the server process has to deal with the incomplete message by buffering it internally, which violates the insertion property. Solution: add a layer of buffer processes, which sends only complete messages to the server. The paper also proves that it is impossible for the client and server to know that they are in mutual agreement about the status of the original message from client to the server. The implication is that it is not necessary to send status information more than once, because no matter how many times you send the status and ACK of the status, you can never be sure that you are in mutual agreement with each other. Strengths of the paper: The insertion property is strict but helpful. By exposing limited and general primitives to the application layer, we can easily insert service layers on the communication path without interfering with the users. We have seen a beautiful layer of buffer processes, which spare the service process the trouble to provide internal buffering for partial transfers. One can further imagine that, when the load is big, we may add a layer of load-balancing dispatcher processes, without interfering with the client or the server. This powerful insulation and abstraction allows for maximum forward compatibility. The use of concurrent programming to increase the throughput. The design of buffer processes allows a service process to use the RECEIVE primitive concurrently. This is a huge improvement in terms of throughput, now that a service process doesn’t have to receive messages one by one. This is concurrency on the communication layer, and with the potential implementation of concurrency within the service process itself, the overall efficiency of this CS model is good. Weaknesses of the paper: If the clients keep sending requests when the server is already busy, the service process may well run out of buffer space, and data may be lost. Some traffic control may be desirable to ensure that there is enough capacity on the server side. The overhead induced by dynamic creation of buffer processes is costly. It may be an optimization to use a dynamic process pool, or even a thread pool for buffering partial transfers, which reduces the overhead of process creation, and provides a cap for server capacity. The time-out feature is necessary in the CS model, for reasons aforementioned, but the exact time-out window could potentially be optimized by adding a failure detection layer. By dynamically calculating the estimated arrival time, we may be able to improve the completeness and accuracy of the time-out feature.","link":"/2023/02/17/paper-reading---cs-model---some-constraints-and-tradeoffs-in-the-design-of-network-communications/"}],"tags":[{"name":"Distribute Systems","slug":"Distribute-Systems","link":"/tags/Distribute-Systems/"},{"name":"Operating Systems","slug":"Operating-Systems","link":"/tags/Operating-Systems/"}],"categories":[],"pages":[{"title":"categories","text":"","link":"/categories/index.html"},{"title":"tags","text":"","link":"/tags/index.html"}]}