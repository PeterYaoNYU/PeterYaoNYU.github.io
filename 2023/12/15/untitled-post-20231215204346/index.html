<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>None | Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697989910010110210">
<meta property="og:type" content="article">
<meta property="og:title" content="None">
<meta property="og:url" content="http://example.com/2023/12/15/untitled-post-20231215204346/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697989910010110210">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-12-15T12:55:09.299Z">
<meta property="article:modified_time" content="2023-12-15T12:55:09.300Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<meta name="generator" content="Hexo 7.0.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS Feed"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="Search"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-untitled-post-20231215204346" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/12/15/untitled-post-20231215204346/" class="article-date">
  <time class="dt-published" datetime="2023-12-15T12:55:09.299Z" itemprop="datePublished">2023-12-15</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      None
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br></pre></td><td class="code"><pre><span class="line">% THIS TEMPLATE IS A WORK IN PROGRESS</span><br><span class="line">% Adapted from an original template by faculty at Reykjavik University, Iceland</span><br><span class="line"></span><br><span class="line">\documentclass&#123;scrartcl&#125;</span><br><span class="line">\input&#123;File_Setup.tex&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">\begin&#123;document&#125;</span><br><span class="line">%Title of the report, name of coworkers and dates (of experiment and of report).</span><br><span class="line">\begin&#123;titlepage&#125;</span><br><span class="line">	\centering</span><br><span class="line">	\includegraphics[width=0.6\textwidth]&#123;nyush-logo.jpeg&#125;\par</span><br><span class="line">	\vspace&#123;2cm&#125;</span><br><span class="line">	%%%% COMMENT OUT irrelevant lines among the 3 below</span><br><span class="line">	&#123;\scshape\LARGE Computer Science \par&#125;  %if you&#x27;re a CS major</span><br><span class="line">	\vspace&#123;1cm&#125;</span><br><span class="line">	&#123;\scshape\Large DURF Report - Summer 2023\par&#125;</span><br><span class="line">	%&#123;\large \today\par&#125;</span><br><span class="line">	\vfill</span><br><span class="line">	</span><br><span class="line">	%%%% PROJECT TITLE</span><br><span class="line">	&#123;\huge\bfseries MLFD: the Implementation and Performance Evaluation of an LSTM-based, SmartNIC-Offloadable Failure Detector\par&#125;</span><br><span class="line">	\vfill</span><br><span class="line">	</span><br><span class="line">	%%%% AUTHOR(S)</span><br><span class="line">	&#123;\Large\itshape Yuncheng Yao&#125;\par</span><br><span class="line">	\vspace&#123;1.5cm&#125;</span><br><span class="line"></span><br><span class="line">	\vfill</span><br><span class="line">	supervised by\par</span><br><span class="line">	%%%% SUPERVISOR(S)</span><br><span class="line">	Olivier Marin</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	\vfill</span><br><span class="line">% Bottom of the page</span><br><span class="line">\end&#123;titlepage&#125;</span><br><span class="line"></span><br><span class="line">\newpage</span><br><span class="line"></span><br><span class="line">\begin&#123;preface&#125;</span><br><span class="line">        I am a Junior from NYU Shanghai, majoring in Computer Science. This report is part of a long running project, which explores the possibility of using machine learning to attain more reliable distributed systems. In this report, I will present the first implementation of an LSTM-based failure detector under real network conditions, and include a performance characterization of the proposed failure detector. </span><br><span class="line">\end&#123;preface&#125;</span><br><span class="line"></span><br><span class="line">\vspace&#123;1cm&#125;</span><br><span class="line"></span><br><span class="line">\begin&#123;acknowledgements&#125;</span><br><span class="line">Acknowledgements allow you to thank those who have helped and supported you during this capstone project, both on a professional and on a personal level. Here you can use a more informal style, as this is not part of the academic work itself.</span><br><span class="line">\end&#123;acknowledgements&#125;</span><br><span class="line"></span><br><span class="line">\newpage</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">\begin&#123;abstract&#125;</span><br><span class="line">This paper explores the feasibility of using machine learning algorithm for failure detection services. Our implementation shows that a DPDK-based failure detector (FD) using long short-term neural network performs well in terms of accuracy, at the cost of reasonable additional computation resources for training and inference. We also show that our implementation can be offloaded to a mainstream SmartNIC - NVIDIA BlueField-2, while retaining comparable quality of service. The viability of offloading ML-FD to SmartNIC further frees up the concern that it will take up too much computation resources. </span><br><span class="line">\end&#123;abstract&#125;</span><br><span class="line">\vspace&#123;1cm&#125;</span><br><span class="line"></span><br><span class="line">\begin&#123;keywords&#125;</span><br><span class="line">\centering</span><br><span class="line">         \textbf&#123;Failure Detectors; SmartNIC; DPDK; LSTM&#125;</span><br><span class="line">\end&#123;keywords&#125;</span><br><span class="line"></span><br><span class="line">\newpage</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">\doublespacing</span><br><span class="line">\tableofcontents</span><br><span class="line">\singlespacing</span><br><span class="line"></span><br><span class="line">\newpage</span><br><span class="line"></span><br><span class="line">\doublespacing</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">\section&#123;Introduction&#125;</span><br><span class="line"></span><br><span class="line">Previous failure detectors\cite&#123;bertier&#125; rely on statistical methods to predict the next arrival of the heartbeat message. They have proven to be computationally efficient, while attaining acceptable quality of service. </span><br><span class="line"></span><br><span class="line">Recent works\cite&#123;ml-fd&#125; show from a data science approach that using LSTM to predict the next heartbeat arrival has even better accuracy than statistical failure detection algorithms, by running the machine learning model on real traces. However, it points out the weakness that the ML-based failure detector&#x27;s computation time is so long that it exceeds the interval between heartbeat messages, rendering the prediction obsolete the moment it is computed. This protracted computation time can be due to numerous factors, including the limited computation resources on the testbeds, the poor utilization of the parallel CPU architecture, improper choices of high-level training parameters like the number of epochs, and the lack of additional heuristics to circumvent unnecessary training. This work also did not take into consideration the additional cost of time in processing network packets, and the burden of running the inference and the training processes at the same time. </span><br><span class="line"></span><br><span class="line">Building on previous work&#x27;s results and limitations, in this paper, we aim to answer the following questions: \textbf&#123;Under realistic data-center settings, with the additional cost incurred by network packet processing and multi-processing, will we be able to implement an LSTM-based failure detector that is computationally efficient, and can generate the prediction in time? If so, compared with statistical failure detectors, what is its cost in terms of CPU and memory resources, and how is its quality of service? Can such a failure detector be offloaded to new hardware like the SmartNICs to further reduce the cost of computation resources?&#125;</span><br><span class="line"></span><br><span class="line">To further free up CPU cycles on the host, we also look for proper hardware to offload the failure detection service to. Emerging SmartNICs come with RDMA enabled network interface cards, multi-core on-board SoC and varying amounts of DRAM. This shows the potential to offload some computational tasks to the SmartNIC itself, rather than interrupting the host CPU to handle the computation. The decision of which part of the computation to offload to the SmartNIC requires careful positioning. Offloading too much computation to the SmartNIC will overwhelm the NIC itself, and may become a bottleneck of the whole system. Performance comparison with existing high performance network solutions like RDMA and DPDK \cite&#123;dpdk&#125; needs to be drawn, to determine if the offloading is worthwhile.</span><br><span class="line"></span><br><span class="line">Offloading failure detectors to the SmartNIC is interesting because:</span><br><span class="line">\begin&#123;enumerate&#125;[label=(\alph*)]</span><br><span class="line">\item It will save host CPU cycles by avoiding interrupting CPUs and having dedicated cores polling for incoming packets.</span><br><span class="line">\item Previous works have shown that SmartNICs achieve even higher throughput than DPDK\cite&#123;xenic&#125;, which demonstrated its potential to handle failure detection within large scale distributed systems with many nodes.</span><br><span class="line">\item Traditional adaptive failure detection algorithms (e.g., Chen&#x27;s FD) \cite&#123;bertier&#125;\cite&#123;chen&#125; are generally small and computationally trivial, making it ideal to be offloaded to the less powerful SmartNIC cores.</span><br><span class="line">\end&#123;enumerate&#125;</span><br><span class="line"></span><br><span class="line">Nvidia Bluefield-2 \cite&#123;bf&#125;, being the current generation of SmartNIC as of writing, has two modes of operation: on-path (embedded) mode and off-path (separate host) mode. In the on-path mode, the SoC sits on the critical path of every network packet. In the off-path mode, the SoC, with its own network stack and operating system, acts as a separate host from the host machine where BlueField is installed. In the off-path mode, the SoC and the host share the same hardware NIC within BlueField-2, but each has independent MAC addresses. A PCIe switch within the BlueField-2 determines where the ingress packets will be directed to. Host and SoC can communicate either via RDMA through the RNIC or DMA through the PCIe link connecting them \cite&#123;off-path&#125;.</span><br><span class="line"></span><br><span class="line">On-path SmartNIC is not the best solution in terms of latency because of its software-defined flow matching property. It is reported to be worse than its RDMA counterpart in terms of latency\cite&#123;xenic&#125;. This should not be a concern because:</span><br><span class="line">\begin&#123;enumerate&#125;[label=(\alph*)]</span><br><span class="line">\item Latency is not an important metric in FD, as long as it is not absurdly long and has an impact on the prediction.</span><br><span class="line">\item Previous work has shown that SmartNIC has even lower latency than RDMA, if PCIe roundtrips to the host DRAM can be reduced, which is feasible since FD is a standalone service that can contain the timestamp data on the SmartNIC DRAM without interacting with the host DRAM.</span><br><span class="line">\end&#123;enumerate&#125;</span><br><span class="line"></span><br><span class="line">Nevertheless, off-path mode is a better choice for implementing a failure detector. Checking whether a packet is intended for failure detection incurs a cost on the overall network performance, and the less powerful SmartNIC SoC is likely to be a bottleneck. Failure detection being a small and standalone service running at the back of a distributed system should not incur a performance tax on all network packet processing. This problem does not exist in the off-path mode, where the failure detection packets are directly forwarded to the SmartNIC SoC, and the performance of network processing on the host is not taxed.</span><br><span class="line"></span><br><span class="line">\begin&#123;center&#125;</span><br><span class="line">\begin&#123;tabular&#125;&#123;|c|c|c|c|c|&#125;</span><br><span class="line">\hline</span><br><span class="line"> &amp; Save CPU Cycles &amp; CPU Computing Power &amp; Latency &amp; Throughput\\</span><br><span class="line">\hline</span><br><span class="line">On-Path DPU &amp; Completely &amp; Weak &amp; Low &amp; High \\</span><br><span class="line">\hline</span><br><span class="line">Off-Path DPU &amp; Completely &amp; Weak &amp; Low &amp; High \\</span><br><span class="line">\hline</span><br><span class="line">One-Sided RDMA &amp; Almost &amp; Completely &amp; High &amp; Low \\</span><br><span class="line">\hline</span><br><span class="line">Two-Sided RDMA &amp; No &amp; High &amp; Low &amp; High \\</span><br><span class="line">\hline</span><br><span class="line">DPDK &amp; No &amp; High &amp; Low &amp; High \\</span><br><span class="line">\hline</span><br><span class="line">Linux Network Stack &amp; No &amp; High &amp; High &amp; Low \\</span><br><span class="line">\hline</span><br><span class="line">\end&#123;tabular&#125;</span><br><span class="line">\end&#123;center&#125;</span><br><span class="line"></span><br><span class="line">Apart from considering which hardware (HW) and software framework (SF) technology we want to accelerate failure detection with, we also compare which failure detection algorithms to use.</span><br><span class="line">\ldots</span><br><span class="line">[Chen/Bertier baseline]</span><br><span class="line">\ldots</span><br><span class="line"></span><br><span class="line">In this paper, we assess the CPU resources and cycles it takes to make a simple LSTM model produce timely predictions of the next heartbeat arrival time. We also evaluate whether new hardware like SmartNIC will be able to train the LSTM model in time. With these experiments, we proclaim that using an LSTM-based failure detection algorithm is feasible in production.</span><br><span class="line"></span><br><span class="line">\section&#123;Experiment Setup&#125;</span><br><span class="line">We use simulation as well as real traces to assess the QoS of different failure detection algorithms. Under the same algorithm, we implement it across DPDK and off-path SmartNIC. </span><br><span class="line"></span><br><span class="line">Besides the QoS of different FD algorithms, the FD program is also profiled using Linux Perf and various other miscellaneous profilers to assess the performance impact it has on the system. </span><br><span class="line"></span><br><span class="line">We begin with a single process \emph&#123;q&#125; monitoring another process \emph&#123;p&#125;. Process p and q are located on 2 nodes within the same cluster, both connected to the same high-speed top-of-rack switch, so the physical message delay is at nano-second level, and the physical message loss rate is statistically negligible. In the first experiment, we assume that message loss and delay follows a certain distribution, and manually simulate the loss and delay on process p. Later we test the accuracy and the detection time of the failure detector on real traces. We also use q to monitor the simulation of many processes, and test how many processes q can monitor at most with different implementations. This test will show how CPU efficient different approaches are. </span><br><span class="line"></span><br><span class="line">Following \cite&#123;chen&#125;, in the simulation, the message loss probability $P_L$ is set to 0.01. The message delay $D$ follows an exponential distribution, i.e., $\Pr(D \leq x) = 1 - e^&#123;-x/E(D)&#125;$ for all $x \geq 0$. This distribution is chosen so that a large portion of messages have fairly short delays. $E(D)$ is chosen to be $30ms$, which should be typical in an Internet setting. The heartbeat interval is set to 100ms, typical of previous research \cite&#123;bertier, ml-fd&#125;. </span><br><span class="line"></span><br><span class="line">We also assess our work on real traces：heartbeat reception logs collected over a week from 9 nodes on the PlanetLab network (http://www.planet-lab.org/). Nodes 1 through 9 send heartbeat messages to node 0 every 100ms. Node 0 keeps track of the reception time on its local clock and the sender whenever a heartbeat message arrives. </span><br><span class="line"></span><br><span class="line">The following QoS metrics will be assessed, which are common to evaluating failure detection algorithms, apparently starting with \cite&#123;chen&#125;.</span><br><span class="line"></span><br><span class="line">\begin&#123;enumerate&#125;[label=(\alph*)]</span><br><span class="line">\item \emph&#123;Detection time ($T_D$)&#125;. We compare for different algorithms and implementation the time that elapses from \emph&#123;p&#125;&#x27;s crash to the time when \emph&#123;q&#125; starts suspecting \emph&#123;p&#125; permanently. This metric is defined with respect to runs with failures, i.e., runs in which we simulate process \emph&#123;p&#125;&#x27;s crashing.</span><br><span class="line">\end&#123;enumerate&#125;</span><br><span class="line"></span><br><span class="line">The following metrics are defined with respect to runs without failures, i.e., we only simulate message delays and loss, but crash failures are not simulated. </span><br><span class="line"></span><br><span class="line">\begin&#123;enumerate&#125;[label=(\alph*)]</span><br><span class="line">\item \emph&#123;Mistake Recurrence Time&#125; ($T_&#123;M_R&#125;$). This measures the time between two consecutive mistakes.</span><br><span class="line">\item \emph&#123;Mistake Duration&#125; &#123;$T_M$&#125;. This measures the time it takes for a FD to correct its mistake.</span><br><span class="line">\item \emph&#123;Query accuracy probability&#125;. This measures the probability that the FD output is correct at random time. It is used for applications that query the FD when there is need.  </span><br><span class="line">\end&#123;enumerate&#125;</span><br><span class="line"></span><br><span class="line">An additional metric is defined for the machine learning based failure detector. \emph&#123;Computation time&#125; ($C_T$), which measure the time that elapses from the point where the heartbeat is received, to the point where the machine learning model puts a prediction of the estimated arrival time ($E_A$) of the next heartbeat. The machine learning approach is only valid if its computation time is smaller than the interval of heartbeats, i.e., the failure detector needs to put an estimate before the next packet arrives. </span><br><span class="line"></span><br><span class="line">For the FD based on ML, we first allow it to scale without limit on the 128-core server (we don&#x27;t use GPU because it is not common for distributed system nodes to have powerful GPU installed), and test how many CPU resources is needed to put an estimate in time. Then the model is migrated to the less powerful 8-core SmartNIC to test if we can offload this FD to the SmartNIC as well. We will further explore the hybrid approach, where the training is done on the host, while the inference is done on the DPU. </span><br><span class="line"></span><br><span class="line">Here is a detailed documentation of how each metric is derived. </span><br><span class="line">    1.  Detection Time: We program the sending process to crash after 10000 heartbeats, an interval long enough for the failure detector to gather enough data and make stable predictions. Because the sender and the FD processes run on different nodes with no synchronized global clock, we model the sender process to fail immediately after sending out the 1500\textsuperscript&#123;th&#125; heartbeat. Since we are working with machines connected to the same switch, the actual network delay is negligible. So $T_D$ = SuspectTime - LastArrival Time + Simulated Network Delay. </span><br><span class="line">    </span><br><span class="line">    2.  Probability of availability: In a run when there is no failure, we log down the number of times a process is suspected. $P_A$ = TimesSuspected / HeartbeatsSent.</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">\section&#123;Related Work&#125;</span><br><span class="line"></span><br><span class="line">An FD is an oracle that tells if a remote process is up or down. In \cite&#123;flp85&#125;, it is proven that in an asynchronous network, it is impossible to determine failure with 100\% certainty. Later \cite&#123;ct96&#125; proposes the idea of using unreliable failure detector to obtain consensus in asynchronous networks. However, in \cite&#123;ct96&#125;, the authors present failure detectors as abstract constructs, rather than any concrete implementation. </span><br><span class="line"></span><br><span class="line">Later \cite&#123;chen&#125; proposes that we should not only consider the completeness and accuracy of the failure detector. Rather, the authors argue that we should also focus on the quality of service of the failure detector. The authors also offer several concrete implementations of the failure detector, one of them being NFD-E, which we later refers to as Chen&#x27;s Estimate. Chen&#x27;s Estimate uses moving averages to estimate the next arrival, and a constant safety margin to prevent too many false positives. Though it does not perform well in term of both accuracy and detection time, it nevertheless serves as a basis for following implementations of failure detectors. </span><br><span class="line"></span><br><span class="line">\cite&#123;bertier&#125; adapts Chen&#x27;s Estimate, modify the constant safety margin to a dynamic one. With this adaptation, the detection time greatly improves. In this paper, we use the Bertier Algorithm as a baseline for comparison. </span><br><span class="line"></span><br><span class="line">\cite&#123;ml-fd&#125; uses data science to approach the failure detection problem. By using a simple layer of LSTM with 4 neurons, the authors train on data from the PlanetLab traces, and are able to achieve good accuracy and detection time. The problem observed is that the computation time is too long that the next arrival estimate is generated after the next heartbeat message arrives. The major shortcoming of the paper is that it does not provide a concrete implementation of a failure detector. The lack of a concrete implementation under real network conditions leads to a lack of performance evaluation, regarding the actual computation cost of an MLFD. It instead explores the feasibility of using LSTM as an underlying network for failure detection, and it turns out to be very hopeful. </span><br><span class="line"></span><br><span class="line">In this short paper, we follow on the work in \cite&#123;ml-fd&#125;. We implement an MLFD with DPDK and Tensorflow. We show that with fast data plane development kit (DPDK) that reduces the waste of  time incurred by interrupting the kernel, and modern machine leaning framework that leverages the power of multi-core systems, we were able to reduce the computation time to less than 100ms. With this implementation, we measure the performance cost of the MLFD. We also port the MLFD to SmartNIC, to see if we can further reduce the tax on systems by offloading the failure detector to extra hardware. </span><br><span class="line"></span><br><span class="line">\section&#123;Solution&#125;</span><br><span class="line"></span><br><span class="line">\begin&#123;figure&#125;[ht]</span><br><span class="line">    \centering</span><br><span class="line">    \includegraphics[width=0.7\linewidth]&#123;desgin dpdk.jpg&#125;</span><br><span class="line">    \caption&#123;Architecture of our MLFD implementation.&#125;</span><br><span class="line">    \label&#123;fig:image_label&#125;</span><br><span class="line">\end&#123;figure&#125;</span><br><span class="line"></span><br><span class="line">Our MLFD implementation consists of three processes running in parallel, so that we can fully utilize the parallelism of the multi-core system. Given the constantly changing network environment and the reasonable complexity of our LSTM model, we chose online training: we continuously update out LSTM model parameters as new timestamp data arrives. </span><br><span class="line"></span><br><span class="line">All inter-process communication between the three processes in out implementation is done via a message queue. This is because: (a) Message queue is memory-based, and is faster than other IPC such as TCP sockets and pipes. (b) Compared with shared memory, message queues save us the trouble and cost of synchronization. (c) Out SmartNIC platform, NVIDIA Bluefield-2, also supports the real-time library that message queeus require, making our program portable to smartNICs. </span><br><span class="line"></span><br><span class="line">When a heartbeat packet first arrives on the NIC, a dedicated DPDK process handles it. We chose DPDK over traditional Linux network stack for three main reasons: (a) by having a dedicated logical core poll the NIC instead of interrupting and trapping into the kernel, DPDK saves the time spent waiting for the scheduler, thus we spare more time for prediction. (b) It may seem redundant to use high-performance tool like DPDK to specifically handle a type of messages that arrive every 100ms, but once the FD is integrated into a bigger distributed system, DPDK can also be responsible to handle more application-level messages. (c) DPDK is portable to mainstream SmartNICs like NVIDIA Bluefield-2. </span><br><span class="line"></span><br><span class="line">If we are training the LSTM model for the first time, or the DPDK program found out that the previous model is no longer suitable for the current network condition, it then send a batch of recent heartbeat arrival time to the training process. </span><br><span class="line"></span><br><span class="line">The criteria of when a model needs a new update can be adapted to suit different levels of need for accuracy and detection time. If within the most recent \textit&#123;k&#125; heartbeats, the false positive rate is $\alpha$ times higher than the false positive rate from the last  \textit&#123;k&#125; heartbeats, or when the false positive rate among the most recent \textit&#123;k&#125; heartbeats is above a certain threshold $\beta$, then the DPDK process knows that the model is no longer suitable for the current network condition, and a new training consisting of several epochs is required. The three parameters, \textit&#123;k&#125;, $\alpha$ and $\beta$ can be customized to suit different need for quality of service. It may seem perplexing about the necessity for a hyper-parameter $\beta$. The $\beta$ in our implementation is to prevent the false positive rate from stabilizing at a high value, and the model never gets trained on more updated data. </span><br><span class="line"></span><br><span class="line">To further reduce the computational cost incurred by training, we adapt the training frequency to the fluctuation of the mean detection time over the last \textit&#123;k&#125; heartbeats. If the mean detection time of the last \textit&#123;k&#125; heartbeats is $\alpha$ times higher than that of the previous \textit&#123;k&#125; heartbeats, or if the mean detection time is higher that a certain threshold $\beta$, then we need to retrain the model with the latest timestamps. </span><br><span class="line"></span><br><span class="line">This feature is based on the observation that data center networks are in a stable phase for most of the time, and that retrain the network whenever there are new packets&#x27; arrival is taxing on the computational resources. </span><br><span class="line"></span><br><span class="line">When we train the new parameters, we don&#x27;t start from a fresh copy of the LSTM model. Instead, we train the new timestamp data on the old model. In this way, we don&#x27;t totally forget the old network pattern, and maybe able to capture the long-term pattern of the network condition with our model. When the training is done, the trained parameters are supplied to the inference process to make predictions. </span><br><span class="line"></span><br><span class="line">The principle of the underlying network used is to make sure that it is as simple and computationally efficient as possible. Time is critical in this use case, and we need to get the computation done before the next heartbeat actually arrives, otherwise the computation is wasted. In this implementation, we use the simple neural network from \cite&#123;ml-fd&#125;, with 1 LSTM layer with 4 neurons and 1 dense layer. </span><br><span class="line"></span><br><span class="line">Meanwhile, whenever there are new heartbeat packet arrival, the DPDK sends the new timestamp to the inference process to make predictions. The inference process then send the prediction back to the DPDK process. </span><br><span class="line"></span><br><span class="line">DPDK process, after receiving the prediction, will fire up a high resolution timer. If the timer expires before the next heartbeat arrives, then the process will be added to the suspect list.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">\section&#123;Results and Discussion&#125;</span><br><span class="line"></span><br><span class="line">The result shows that our implementation of MLFD is significantly better than Bertier&#x27;s Estimate in terms of Accuracy, but performs worse than Bertier&#x27;s Estimate in terms of detection time and the computational resources required. </span><br><span class="line"></span><br><span class="line">\subsection&#123;Experimentation protocol&#125;</span><br><span class="line"></span><br><span class="line">For quality of service of our implementation of the MLFD, we assess its detection time, mistake recurrence rate, mistake duration and query accuracy probability. For each metric, we test it on both the host and the SmartNIC. The host runs on Intel(R) Xeon(R) Gold 6338 CPU, with 128-cores, and 503GB memory. The SmartNIC is a NVIDIA BlueField-2, which runs on 8-core ARM Cortex-A72, and has 15GB on-board memory.</span><br><span class="line"></span><br><span class="line">For each QoS experiment, we use both simulation based on exponential distribution and real PlanetLab traces to compare the performance of different failure detectors. </span><br><span class="line"></span><br><span class="line">Besides QoS, we also evaluate the computation resources required to for out MLFD implementation to work. We monitor the overall cost with Linux Perf, and to gain additional insight into the training and the inference module of our implementation, we use Python cProfile. </span><br><span class="line"></span><br><span class="line">We chose Bertier&#x27;s Estimate\cite&#123;bertier&#125; as a baseline, and follow the recommended parameter setup in the original paper. Bertier has high accuracy and low detection time, and is computationally efficient, since it relies only on simple statistical methods to generate prediction of next arrival, and there is no complex non-linear function as </span><br><span class="line"></span><br><span class="line">\subsection&#123;Query Accuracy Probability&#125;</span><br><span class="line"></span><br><span class="line">When MLFD is run on the host and tested on real traces, the MLFD&#x27;s Query Accuracy probability is significantly better than that of Bertier. On average, the Bertier&#x27;s estimate makes 17.07 false positive predictions every 1000 heartbeats, but out MLFD implementation makes only 0.61 false positive predictions every 1000 heartbeats. </span><br><span class="line"></span><br><span class="line">\begin&#123;figure&#125;[h]</span><br><span class="line">    \includegraphics[scale=0.4]&#123;Graphics/mlfd_bertier_acccuracy_host_traces.png&#125;</span><br><span class="line">    \caption&#123;MLFD vs. Bertier with real traces on Host&#125;</span><br><span class="line">    \label&#123;fig:sample&#125;</span><br><span class="line">\end&#123;figure&#125;</span><br><span class="line"></span><br><span class="line">When MLFD is run on the host and tested with simulation, the result is similarly to that with traces. MLFD makes only 0.097 false positive prediction every 1000 heartbeats.</span><br><span class="line"></span><br><span class="line">[Missing the Bertier Simulation on Host]</span><br><span class="line"></span><br><span class="line">However, high accuracy is not necessarily a good thing. We can achieve infinitely high accuracy as long as we make a prediction in the far future. To evaluate the QoS of MLFD more thoroughly, we need to include an analysis of the detection time.</span><br><span class="line"></span><br><span class="line">\subsection&#123;Detection Time with Dynamic Update Based on Accuracy&#125;</span><br><span class="line"></span><br><span class="line">At first we only consider the accuracy when dynamically deciding when to retrain. In other words, we don&#x27;t retrain if the detection time is very high. We only retrain when the accuracy has become worse than the previous batch, or when the accuracy is below a certain threshold. In other words, as long as the accuracy is reasonable, no matter how high the detection time may be, we don&#x27;t retrain the model. </span><br><span class="line"></span><br><span class="line">When MLFD is run on the host and tested with simulation, we observe that the detection time shows the steady trend to increase overtime, even though the increase gradually flattened. </span><br><span class="line"></span><br><span class="line">\begin&#123;figure&#125;[h]</span><br><span class="line">    \centering</span><br><span class="line">    \resizebox&#123;\textwidth&#125;&#123;!&#125;&#123;\includegraphics&#123;Graphics/detection4.png&#125;&#125;</span><br><span class="line">    \caption&#123;MLFD detection time from simulation, tested on the host, running through 30,000 heartbeats, the mean detection time is 409ms&#125;</span><br><span class="line">    \label&#123;fig:sample&#125;</span><br><span class="line">\end&#123;figure&#125;</span><br><span class="line"></span><br><span class="line">The above picture shows the detection time for one run of the MLFD. For every prediction made, we measure the gap between the predicted arrival time and the actual arrival time with blue dots (the detection time). The vertical black dashed line indicate the time when a retraining of the model occurs. The horizontal green dashed line marks the average detection time in this run. The curved red line shows a regression of the detection time over the course of the run. </span><br><span class="line"></span><br><span class="line">This inflation of detection time may be of several reasons. Either we are not retraining enough to adapt to fact that the detection time is very high, which can be counteracted by a dynamic retrain mechanism that takes into account the detection time, or retrain every few hundred heartbeats, without considering the current accuracy and detection time; or we are suffering from the recurrent nature of the LSTM neural network that we chose. Because we keep feeding the LSTM neuron with a summary of history information, for some deep reason that is hard to discern, the network predicts in a direction that is less likely to lead to a negative next arrival prediction. The second hypothesis can be tested and potentially corroborated by enlarging the retrain period, or by adopting a simple fully connected neural network without recurrent neurons, and observe if the inflation of detection time persists. </span><br><span class="line"></span><br><span class="line">\begin&#123;figure&#125;[h]</span><br><span class="line">    \centering</span><br><span class="line">    \resizebox&#123;\textwidth&#125;&#123;!&#125;&#123;\includegraphics&#123;Graphics/detection_time5.png&#125;&#125;</span><br><span class="line">    \caption&#123;MLFD detection time from real traces, tested on the host, running through over 600,000 heartbeats, the mean detection time is 409ms, the median detection time is 4091ms&#125;</span><br><span class="line">    \label&#123;fig:sample&#125;</span><br><span class="line">\end&#123;figure&#125;</span><br><span class="line"></span><br><span class="line">This effect is even more salient when we train the model over longer time. The MLFD&#x27;s mean detection time can be over 4000ms when it is tested over 600,000 heartbeats, a detection time that is unacceptable, given that the heartbeat interval is only 100ms. Over larger time scales, the data seems to suggest that the first hypothesis, which suggests that we are not retraining enough when the detection time is high, has a larger effect than the assumption that the recurrent nature of the LSTM is contributing to the inflating detection time. It seems that the detection time is quite stable in between each retraining, which indicates that the recurrent neurons are not contributing much to the inflating detection time. But in between retraining, we observe a leap in detection time. </span><br><span class="line"></span><br><span class="line">To circumvent the inflation of detection time, we propose two methods. We can train the model continuously, regardless of how well the model performs in terms of accuracy. Even though this takes significantly more CPU cycles, with the constant training, we should eventually obtain a model whose parameters yield short detection time. We can also take detection time into consideration when we are deciding whether to retrain the model or not. In this way, we should save the clock cycles wasted by the excessive retraining, while maintaining reasonable detection time. </span><br><span class="line"></span><br><span class="line">To further reduce the detection time, we adjust the penalty incurred on a negative prediction. In this way we hope that this will train the model in a way that yields smaller detection time. </span><br><span class="line"></span><br><span class="line">\subsection&#123;Detection Time with Continuous Update&#125;</span><br><span class="line"></span><br><span class="line">To avoid the inflation of detection time problem from the previous section, we train the model continuously every 200 heartbeats, without considering the current accuracy and detection time. We also adapt the penalty incurred on negative predictions, to further explore the trade-off between accuracy and detection time. As a comparison, we use the Bertier Estimate. </span><br><span class="line"></span><br><span class="line">\begin&#123;table&#125;[ht]</span><br><span class="line">    \centering</span><br><span class="line">    \begin&#123;tabular&#125;&#123;lcccccr&#125;</span><br><span class="line">        \hline</span><br><span class="line">        \multicolumn&#123;1&#125;&#123;c&#125;&#123;Detection Time&#125; &amp; &amp; &amp; &amp; &amp;\\</span><br><span class="line">        \hline  </span><br><span class="line">        Percentile &amp; penalty=$10^6$ &amp; penalty=$10^4$ &amp; penalty=$10^3$ &amp; penalty=$10^2$ &amp; Bertier &amp;\\</span><br><span class="line">        \hline</span><br><span class="line">        10th &amp; \SI&#123;89.01&#125;&#123;\ms&#125; &amp; \SI&#123;5.52&#125;&#123;\ms&#125; &amp; \SI&#123;0.92&#125;&#123;\ms&#125; &amp; \SI&#123;0.19&#125;&#123;\ms&#125; &amp; \SI&#123;0.25&#125;&#123;\ms&#125; &amp;\\</span><br><span class="line">        25th &amp; \SI&#123;218.86&#125;&#123;\ms&#125; &amp; \SI&#123;24.61&#125;&#123;\ms&#125; &amp; \SI&#123;2.59&#125;&#123;\ms&#125; &amp; \SI&#123;0.49&#125;&#123;\ms&#125; &amp; \SI&#123;0.38&#125;&#123;\ms&#125; &amp;\\</span><br><span class="line">        50th &amp; \SI&#123;376.62&#125;&#123;\ms&#125; &amp; \SI&#123;119.80&#125;&#123;\ms&#125; &amp; \SI&#123;7.72&#125;&#123;\ms&#125; &amp; \SI&#123;1.53&#125;&#123;\ms&#125; &amp; \SI&#123;0.52&#125;&#123;\ms&#125; &amp;\\</span><br><span class="line">        75th &amp; \SI&#123;444.82&#125;&#123;\ms&#125; &amp; \SI&#123;283.36&#125;&#123;\ms&#125; &amp; \SI&#123;115.08&#125;&#123;\ms&#125; &amp; \SI&#123;20.03&#125;&#123;\ms&#125; &amp; \SI&#123;0.73&#125;&#123;\ms&#125; &amp;\\</span><br><span class="line">        90th &amp; \SI&#123;596.96&#125;&#123;\ms&#125; &amp; \SI&#123;492.57&#125;&#123;\ms&#125; &amp; \SI&#123;224.85&#125;&#123;\ms&#125; &amp; \SI&#123;126.69&#125;&#123;\ms&#125; &amp; \SI&#123;1.3&#125;&#123;\ms&#125; &amp;\\</span><br><span class="line">        \hline</span><br><span class="line">        False Positives \\(per 1000 heartbeats) &amp; 0.95 &amp; 7.43 &amp; 14 &amp; 50.38 &amp; 15.58 &amp;\\</span><br><span class="line">        \hline</span><br><span class="line">    \end&#123;tabular&#125;</span><br><span class="line">    \caption&#123;Comparison of detection time with different penalty on negative predictions and with the Bertier Estimate, tested on the host machine with real traces&#125;</span><br><span class="line">    \label&#123;tab:my_label&#125;</span><br><span class="line">\end&#123;table&#125;</span><br><span class="line"></span><br><span class="line">As suggested in Table 1, lower penalty for negative predictions does lead to lower prediction time, but at the cost of lower accuracy. Conversely, if higher accuracy is desired, the detection time can be prohibitively long. On the contrary, unlike our MLFD implementation, which fails to find a balance between detection time and accuracy, the baseline Bertier Estimate has reasonable false positive rate, but with very small detection time. </span><br><span class="line"></span><br><span class="line">It seems that, from a quality of service prospective, Bertier performs much better than our MLFD implementation. This is a fair comparison, because we are now retraining the model excessively, and the model should never get stale. Even in this case, the MLFD cannot yield comparable performance with the Bertier Estimate. This indicates that a fundamental change to the underlying neural network is needed, if at all possible, if we want to pursue machine learning as a solution for failure detection. </span><br><span class="line"></span><br><span class="line">\begin&#123;figure&#125;[h]</span><br><span class="line">    \centering</span><br><span class="line">    \resizebox&#123;\textwidth&#125;&#123;!&#125;&#123;\includegraphics&#123;Graphics/periodic_detection_time.png&#125;&#125;</span><br><span class="line">    \caption&#123;MLFD detection time from real traces, tested on the host, update the model continuously, with a penalty rate of $10^3$ for negative predictions&#125;</span><br><span class="line">    \label&#123;fig:sample&#125;</span><br><span class="line">\end&#123;figure&#125;</span><br><span class="line"></span><br><span class="line">\begin&#123;figure&#125;[h]</span><br><span class="line">    \centering</span><br><span class="line">    \resizebox&#123;\textwidth&#125;&#123;!&#125;&#123;\includegraphics&#123;Graphics/bertier_detection_time.png&#125;&#125;</span><br><span class="line">    \caption&#123;Detection time of the Bertier Estimate from real traces, tested on the host&#125;</span><br><span class="line">    \label&#123;fig:sample&#125;</span><br><span class="line">\end&#123;figure&#125;</span><br><span class="line"></span><br><span class="line">Meanwhile, it is worth noticing that the MLFD detection time is less stable than that of the Bertier&#x27;s Estimate, and exhibits periodic patterns. When we retrain the LSTM model every few hundred heartbeats, the detection time enters into a new stable phase, with the detection time being stable for different heartbeats within that phase. The stable phase is interrupted whenever we retrain the model. This exhibits an undesirable feature of the MLFD: the detection time in between different phases is unstable. In other words, even if the detection time of our MLFD implementation is low for a majority of the time, it can yield high detection time. Table 1 corroborates this idea: MLFD shows a much higher tail detection time than Bertier Estimate. </span><br><span class="line"></span><br><span class="line">On the other hand, the Bertier Estimate shows very high detection time when the network condition changes, but is able to converge to a low detection time very quickly. In addition, once it converges to a low detection time, it remains stable, unless the network condition changes. </span><br><span class="line"></span><br><span class="line">\subsection&#123;Detection Time with Dynamic Update Based on Accuracy and Detection Time&#125;</span><br><span class="line"></span><br><span class="line">In hope to find a better balance between computation time, accuracy and detection time, we also chose when to update our model based on not only mean accuracy, but also mean detection time from the last 200 heartbeats. We now retrain the model, either when the mean detection time has gone worse, or when the mean accuracy has gone worse. Either case is an indication that our network condition has changed, and a round of retraining is needed for better quality of service. We hope that with this design, we will not only be able to gain the saving on CPU cycles by retraining only when it is needed, but also attain better QoS compared to only retraining when the accuracy has gone worse: we are now taking more QoS metrics into consideration. </span><br><span class="line"></span><br><span class="line">Based on the analysis from last section, we compare the detection time and accuracy for the MLFD with a penalty of $10^2$ and $10^3$. We chose these two parameters because a $10^3$ penalty rate has comparable accuracy with Bertier Estimate, which allows for a fair comparison of detection time when the accuracy of these two methods are on par with each other. With a $10^2$ penalty, we are able to attain best detection time, which will give us insight into how MLFD performs in terms of accuracy when the detection time is minimal in MLFD. </span><br><span class="line"></span><br><span class="line">\begin&#123;table&#125;[ht]</span><br><span class="line">    \centering</span><br><span class="line">    \begin&#123;tabular&#125;&#123;lcccr&#125; % Added an additional &#x27;c&#x27; column specifier</span><br><span class="line">        \hline</span><br><span class="line">        \multicolumn&#123;1&#125;&#123;c&#125;&#123;Detection Time: Dynamic Update&#125; &amp; &amp; &amp;\\</span><br><span class="line">        \hline  </span><br><span class="line">        Percentile &amp; penalty=$10^3$ &amp; penalty=$10^2$ &amp; Bertier &amp;\\</span><br><span class="line">        \hline</span><br><span class="line">        10th &amp; \SI&#123;2.57&#125;&#123;\ms&#125; &amp; \SI&#123;0.32&#125;&#123;\ms&#125; &amp; \SI&#123;0.25&#125;&#123;\ms&#125; &amp;\\</span><br><span class="line">        25th &amp; \SI&#123;5.81&#125;&#123;\ms&#125; &amp; \SI&#123;0.81&#125;&#123;\ms&#125; &amp; \SI&#123;0.38&#125;&#123;\ms&#125; &amp;\\</span><br><span class="line">        50th &amp; \SI&#123;58.30&#125;&#123;\ms&#125; &amp; \SI&#123;3.68&#125;&#123;\ms&#125; &amp; \SI&#123;0.52&#125;&#123;\ms&#125; &amp;\\</span><br><span class="line">        75th &amp; \SI&#123;126.42&#125;&#123;\ms&#125; &amp; \SI&#123;33.62&#125;&#123;\ms&#125; &amp; \SI&#123;0.73&#125;&#123;\ms&#125; &amp;\\</span><br><span class="line">        90th &amp; \SI&#123;166.79&#125;&#123;\ms&#125; &amp; \SI&#123;127.56&#125;&#123;\ms&#125; &amp; \SI&#123;1.3&#125;&#123;\ms&#125; &amp;\\</span><br><span class="line">        \hline</span><br><span class="line">        False Positives \\(per 1000 heartbeats) &amp; 5.919 &amp; 25.25 &amp; 15.58 &amp;\\</span><br><span class="line">        \hline</span><br><span class="line">    \end&#123;tabular&#125;</span><br><span class="line">    \caption&#123;Comparison of detection time with Dynamic Update MLFD (based on both the detection time and the accuracy) and with the Bertier Estimate, tested on the host machine with real traces&#125;</span><br><span class="line">    \label&#123;tab:my_label&#125;</span><br><span class="line">\end&#123;table&#125;</span><br><span class="line"></span><br><span class="line">What we observe from Table 2 is that with the dynamic update mechanism that takes into account both the detection time and the accuracy, the accuracy has significantly improved without sacrificing too much on detection time. The detection time has gone worse, but also has smaller variance. Because with dynamic update of the model, we are actually training less. Hence, the improvement in accuracy is more likely a result of the degradation of detection time. We also discover that with more frequent training, we have better median detection time, but the variance of the detection time is also bigger. </span><br><span class="line"></span><br><span class="line">We could further lower the detection time by fine tuning the parameters and make our MLFD more sensitive to the degradation in detection time, and retrain more frequently. However, this will go against our purpose to save CPU cycles during stable phases. </span><br><span class="line"></span><br><span class="line">\subsection&#123;A Short Summary On Detection Time&#125;</span><br><span class="line">It seems that, in all cases, the overall performance of MLFD in terms of quality of service is worse than that of the Bertier Estimate. Whenever the accuracy is better than Bertier, the detection time is always significantly worse. Further, it is often the case that both the detection time and the accuracy is worse than the Bertier Estimate. </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">\subsection&#123;Computation Time&#125;</span><br><span class="line">We ran the test of computation time over 350000 heartbeats on the host. We measure the average computation time, which is the average time it takes for a failure detector to generate a prediction to the next heartbeat arrival, and the late prediction rate, which is the percentage of predictions that is made after the next heartbeat arrives. Here we omit the computation time for the Bertier Estimate, because it is computationally trivial. </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">\begin&#123;table&#125;[ht]</span><br><span class="line">    \centering</span><br><span class="line">    \begin&#123;tabular&#125;&#123;lccr&#125; % Added an additional &#x27;c&#x27; column specifier</span><br><span class="line">        \hline</span><br><span class="line">        \multicolumn&#123;1&#125;&#123;c&#125;&#123;Computation Time&#125; &amp; &amp; &amp;\\</span><br><span class="line">        \hline  </span><br><span class="line">        Percentile &amp; Host &amp; SmartNIC&amp;\\</span><br><span class="line">        \hline</span><br><span class="line">        1th &amp; \SI&#123;66.36&#125;&#123;\ms&#125; &amp; \SI&#123;&#125;&#123;\ms&#125; &amp; \\</span><br><span class="line">        25th &amp; \SI&#123;68.51&#125;&#123;\ms&#125; &amp; \SI&#123;&#125;&#123;\ms&#125; &amp;\\</span><br><span class="line">        50th &amp; \SI&#123;69.58&#125;&#123;\ms&#125; &amp; \SI&#123;&#125;&#123;\ms&#125; &amp;\\</span><br><span class="line">        75th &amp; \SI&#123;70.84&#125;&#123;\ms&#125; &amp; \SI&#123;&#125;&#123;\ms&#125; &amp;\\</span><br><span class="line">        99th &amp; \SI&#123;75.18&#125;&#123;\ms&#125; &amp; \SI&#123;&#125;&#123;\ms&#125; &amp;\\</span><br><span class="line">        \hline</span><br><span class="line">        Late Predictions \\(per 1000 heartbeats) &amp; 2.09 &amp; 7.43&amp;\\</span><br><span class="line">        \hline</span><br><span class="line">    \end&#123;tabular&#125;</span><br><span class="line">    \caption&#123;Comparison of computation time on different hardware, when the system load is low&#125;</span><br><span class="line">    \label&#123;tab:my_label&#125;</span><br><span class="line">\end&#123;table&#125;</span><br><span class="line"></span><br><span class="line">\subsection&#123;CPU Load and Cycles&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">\section&#123;Discussion&#125;</span><br><span class="line">The discussion section focuses on the main challenges/issues you had to overcome during the project. Outline what your approach does better than the ones you mentioned in your related work, and explain why. Do the same with issues where other solutions  outperform your own. Are there limitations to your approach? If so, what would you recommend towards removing/mitigating them? Given the experience you&#x27;ve gathered working on this project, are there other approaches that you feel are worth exploring?</span><br><span class="line"></span><br><span class="line">\section&#123;Conclusion&#125;</span><br><span class="line"></span><br><span class="line">Give a clear, short, and informative summary of all your important results. Answer the initial question(s) or respond to what you wanted to do, as stated in your introduction. It can be a short table or a list, and possibly one or two short comments or explanations. </span><br><span class="line"></span><br><span class="line">Target a reader who may not have time to read the whole report yet, but needs the results or the conclusions immediately. This is a typical situation in real life. Some readers will read your introduction and skip to your conclusion first, and read the whole report only later (if at all).</span><br><span class="line"></span><br><span class="line">You may also draw perspectives. What&#x27;s missing? In what directions could your work be extended?</span><br><span class="line"></span><br><span class="line">\newpage</span><br><span class="line">\singlespacing</span><br><span class="line">\bibliographystyle&#123;IEEEtran&#125;</span><br><span class="line">\bibliography&#123;references&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">%------ To create Appendix with additional stuff -------%</span><br><span class="line">%\newpage</span><br><span class="line">%\appendix</span><br><span class="line">%\section&#123;Appendix&#125;</span><br><span class="line">%Put data files, CAD drawings, additional sketches, etc.</span><br><span class="line"></span><br><span class="line">\end&#123;document&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>


      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2023/12/15/untitled-post-20231215204346/" data-id="clq6muyga0004agc37ukd0m0n" data-title="None" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/2023/12/15/hello-world/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Hello World</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/12/">December 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/05/">May 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/02/">February 2023</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2023/12/15/untitled-post-20231215204346/">None</a>
          </li>
        
          <li>
            <a href="/2023/12/15/hello-world/">Hello World</a>
          </li>
        
          <li>
            <a href="/2023/07/10/cmu15-213-attack-lab/">CMU15-213 Attack Lab</a>
          </li>
        
          <li>
            <a href="/2023/05/18/bomb-lab-cmu-15-213/">Bomb Lab CMU 15-213</a>
          </li>
        
          <li>
            <a href="/2023/02/17/paper-reading---cs-model---some-constraints-and-tradeoffs-in-the-design-of-network-communications/">Paper Reading - CS Model - Some constraints and tradeoffs in the design of network communications</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2023 John Doe<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>